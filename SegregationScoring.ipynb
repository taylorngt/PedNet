{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["KBxiRyiFWqXw","U3iisDMaYWZj","wZuGOFdRabR1","IkjU5ec4asuu","cvyvTNF7cfmc","kYcXKMyuwj22","YZ_NP-9adN_O","jtIyHxUSLlqN"],"mount_file_id":"1ODGtCL1RD4AUrJx96JoioTVgQajy3IOK","authorship_tag":"ABX9TyO0pg7sh8tALtNq4BTMPDxY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#I. Machine Prep"],"metadata":{"id":"KBxiRyiFWqXw"}},{"cell_type":"code","source":["%pip install pandas\n","!apt install graphviz libgraphviz-dev\n","%pip install pygraphviz\n","%pip install powerlaw\n","%pip install networkx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnHmewk_LcCf","executionInfo":{"status":"ok","timestamp":1752749182972,"user_tz":-60,"elapsed":26207,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"42e1b7cd-6450-47f2-d88f-22d64c324479"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","graphviz is already the newest version (2.42.2-6ubuntu0.1).\n","libgraphviz-dev is already the newest version (2.42.2-6ubuntu0.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (1.14)\n","Requirement already satisfied: powerlaw in /usr/local/lib/python3.11/dist-packages (1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from powerlaw) (1.15.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from powerlaw) (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from powerlaw) (3.10.0)\n","Requirement already satisfied: mpmath in /usr/local/lib/python3.11/dist-packages (from powerlaw) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->powerlaw) (1.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n"]}]},{"cell_type":"code","source":["import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from sklearn.metrics import accuracy_score, auc\n","import pprint\n","import numpy as np\n","from collections import OrderedDict\n","import powerlaw\n","import itertools as it\n","from typing import Dict, Set, Tuple\n","from scipy.optimize import minimize\n","import copy\n","from pprint import pprint"],"metadata":{"id":"Kdpq9BulYHKk","executionInfo":{"status":"ok","timestamp":1752749182990,"user_tz":-60,"elapsed":2,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["#II. Pedigree Graph Conversion"],"metadata":{"id":"U3iisDMaYWZj"}},{"cell_type":"code","source":["def pedfile_readin(pedfile):\n","    cols = ['FamilyID', 'IndividualID', 'PaternalID', 'MaternalID', 'Sex', 'Phenotype', 'Genotype']\n","    df = pd.read_csv(pedfile, sep=r'\\s+', header=None, names=cols)\n","    return df\n","\n","\n","def construct_pedigree_graph(df, rm_floaters= True):\n","    G = nx.DiGraph()\n","\n","    all_parents_set = set()\n","    founder_set = set()\n","\n","    for _, row in df.iterrows():\n","        # Make sure IndividualID is treated as a string or int consistently if needed\n","        G.add_node(row['IndividualID'],\n","                  family=row['FamilyID'],\n","                  sex=row['Sex'],\n","                  phenotype=row['Phenotype'])\n","\n","    for _, row in df.iterrows():\n","        # Ensure PaternalID and MaternalID are compared to string '0' if they are strings\n","        paternal_id = row['PaternalID']\n","        maternal_id = row['MaternalID']\n","        individual_id = row['IndividualID']\n","\n","        if paternal_id != 0:\n","            G.add_edge(paternal_id, individual_id)\n","            all_parents_set.add(paternal_id)\n","        if maternal_id != 0:\n","            G.add_edge(maternal_id, individual_id)\n","            all_parents_set.add(maternal_id)\n","        if maternal_id == 0 and paternal_id == 0:\n","            founder_set.add(individual_id)\n","\n","    #Removing founders with no children (i.e. floaters)\n","    if rm_floaters:\n","        floaters_set = founder_set - all_parents_set\n","        G.remove_nodes_from(floaters_set)\n","\n","\n","    return G"],"metadata":{"id":"6sV8J9aiYa5w","executionInfo":{"status":"ok","timestamp":1752749182999,"user_tz":-60,"elapsed":2,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["###Pedigree Graph Visualization"],"metadata":{"id":"qFh3pZrXYjCq"}},{"cell_type":"code","source":["def plot_pedigree_tree(G, title=\"Pedigree (Tree Layout)\"):\n","    try:\n","        from networkx.drawing.nx_agraph import graphviz_layout\n","        pos = graphviz_layout(G, prog='dot')  # 'dot' gives top-down DAG style\n","    except ImportError:\n","        print(\"PyGraphviz not installed. Falling back to spring layout.\")\n","        pos = nx.spring_layout(G, seed=42)\n","\n","    node_colors = ['red' if G.nodes[n]['phenotype'] == 2 else 'lightblue' for n in G.nodes]\n","\n","    nx.draw(G, pos, with_labels=True, node_color=node_colors, arrows=True)\n","    plt.title(title)\n","    plt.show()"],"metadata":{"id":"r0R4dLLLYmbk","executionInfo":{"status":"ok","timestamp":1752749183030,"user_tz":-60,"elapsed":30,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["#III. Pedigree Graph Analysis"],"metadata":{"id":"wZuGOFdRabR1"}},{"cell_type":"markdown","source":["###Simple Pedigree Helper Functions"],"metadata":{"id":"IkjU5ec4asuu"}},{"cell_type":"code","source":["def parents(G, node):\n","    \"\"\"Return a list of parent nodes for `node` (incoming edges).\"\"\"\n","    return list(G.predecessors(node))\n","\n","def siblings(G, node):\n","    \"\"\"Return siblings: nodes that share ≥ 1 parent with `node`.\"\"\"\n","    sibs = set()\n","    for p in parents(G, node):\n","        sibs.update(G.successors(p))\n","    sibs.discard(node)\n","    return sibs\n","\n","def children(G, node):\n","    \"\"\"Return a list of child nodes for `node` (outgoing edges).\"\"\"\n","    return list(G.successors(node))\n","\n","def generations(G):\n","    lvl={}\n","    Q=[(n,0) for n in G if G.in_degree(n)==0]\n","    while Q:\n","        n,d=Q.pop(0)\n","        #this check doesnt take into account children produced from one founder and one relative\n","        #leads all individuals to have the generation count to be minimum distance from most recent founder\n","        #if n in lvl: continue\n","        lvl[n]=d\n","        for c in G.successors(n): Q.append((c,d+1))\n","    return lvl\n","\n","def aff(G):\n","    return [n for n in G.nodes if G.nodes[n]['phenotype']==2]\n","def unaff(G):\n","    return [n for n in G.nodes if G.nodes[n]['phenotype']==1]\n"],"metadata":{"id":"buKtIoswapHo","executionInfo":{"status":"ok","timestamp":1752749183033,"user_tz":-60,"elapsed":4,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["###Pedigree Feature Extraction and Metric Calculation"],"metadata":{"id":"cvyvTNF7cfmc"}},{"cell_type":"code","source":["#################### MODULAR PEDIGREE FEATURES ####################\n","'''\n","Features: measures based on inheritence patterns gleaned from pedigree data alone,\n","no use of genotype or graph-specific data\n","\n","Current List of Features:\n","-------------------------\n","1. Ratio Affected Parents\n","2. Generation Coverage\n","3. Affected Sibling Clustering\n","4. Average Betweeness of Unaffected\n","5. Average Betweeness of Carriers (CURRENTLY EXCLUDED)\n","6. Average Betweeness of Carriers in Affected+Carrier Subgraph (CURRENTLY EXCLUDED)\n","'''\n","\n","# ---------------------------------------------------------------------\n","# 1. Ratio Affected Parents\n","# ---------------------------------------------------------------------\n","def ratio_aff_parents(G):\n","    aff_nodes = aff(G)\n","    aff_aff_partent = 0\n","    for n in aff_nodes:\n","        if any(G.nodes[p]['phenotype']==2 for p in parents(G,n)):\n","            aff_aff_partent +=1\n","    return aff_aff_partent/len(aff_nodes) if aff_nodes else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 2. Generation Coverage\n","# ---------------------------------------------------------------------\n","def gen_cov(G):\n","    gen = generations(G)\n","    gens_aff = {gen[n] for n in aff(G)}\n","    return len(gens_aff)/(max(gen.values())+1) if gen else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 3. Affected Sibling Clustering\n","# ---------------------------------------------------------------------\n","def sibling_aff_ratio(G):\n","    sib_pairs=0; aa_pairs=0\n","    for n in aff(G):\n","        for sib in siblings(G,n):\n","            if sib in aff(G):\n","                aa_pairs+=1\n","            sib_pairs+=1\n","    return aa_pairs/sib_pairs if sib_pairs else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 4. Average Betweeness of Unaffected\n","# ---------------------------------------------------------------------\n","def avg_bet_unaff(G):\n","    unaffecteds = unaff(G)\n","    bet = nx.betweenness_centrality(G)\n","    return np.mean([bet[n] for n in unaffecteds]) if unaffecteds else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 5. Average Betweeness of Carriers\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","# def avg_bet_carrier(G):\n","#     carriers = [n for n in unaff(G) if G.nodes[n]['phenotype'] == 1]\n","#     bet = nx.betweenness_centrality(G)\n","#     return np.mean([bet[n] for n in carriers]) if carriers else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 6. Average Betweeness of Carriers in Affected+Carrier Subgraph\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","# def avg_bet_carrier_subgraph(G):\n","#     aff_nodes = aff(G)\n","#     unaff_nodes = unaff(G)\n","#     carrier_nodes = [n for n in unaff_nodes if G.nodes[n]['genotype'] == 1]\n","#     bet = nx.betweenness_centrality(G.subgraph(aff_nodes+carrier_nodes))\n","#     return np.mean([bet[n] for n in carrier_nodes]) if carrier_nodes else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# PEDIGREE FEATURES WRAPPER\n","# ---------------------------------------------------------------------\n","def pedigree_features(G):\n","    return {\n","        'ratio_aff_parent': ratio_aff_parents(G),\n","        'gen_cov': gen_cov(G),\n","        'sibling_aff_ratio': sibling_aff_ratio(G),\n","        'avg_bet_unaff': avg_bet_unaff(G),\n","\n","        # See exclusion reasoning in function description above\n","        #'avg_bet_carrier': avg_bet_carrier(G),\n","        #'avg_bet_carrier_subgraph': avg_bet_carrier_subgraph(G)\n","    }\n","\n"],"metadata":{"id":"qkY1ab3PcxCl","executionInfo":{"status":"ok","timestamp":1752749183034,"user_tz":-60,"elapsed":1,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["#################### MODULAR GRAPH METRICS ####################\n","'''\n","Metrics: measures based on network structure and phenotype data independent of genotype data\n","\n","Current List of Metrics:\n","-------------------------\n","1. Number of Nodes\n","2. Number of Edges\n","3. Number of Connected Components\n","4. Average Clustering Coefficient\n","5. Diameter\n","6. Average Shortest Path Length\n","7. Average Degree Centrality\n","8. Average Betweenness Centrality\n","9. Average Closeness Centrality\n","10. Power Law Alpha  (CURRENTLY EXCLUDED)\n","11. Power Law Xmin  (CURRENTLY EXCLUDED)\n","12. Sigma Small World (CURRENTLY EXCLUDED)\n","13. Pedigree Width\n","14. Number of Edges of Transitive Reduction\n","15. Transitive Reduction Size Ratio\n","16. Longest Path Length\n","17. Minimal Founder Coverage Size\n","18. Founder Influence\n","'''\n","\n","# ---------------------------------------------------------------------\n","# 1. Basic Graph Metrics\n","# ---------------------------------------------------------------------\n","def basic_graph_metrics(G):\n","    G_u = G.to_undirected()\n","    return {\n","        'n_nodes': G.number_of_nodes(),\n","        'n_edges': G.number_of_edges(),\n","        'n_components': nx.number_connected_components(G_u),\n","        'avg_clustering': nx.average_clustering(G_u),\n","        'diameter': nx.diameter(G_u),\n","        'avg_path_len': nx.average_shortest_path_length(G_u)\n","    }\n","\n","# ---------------------------------------------------------------------\n","# 2. Centralities\n","# ---------------------------------------------------------------------\n","def centralities(G):\n","    G_u = G.to_undirected()\n","    deg_cent = list(nx.degree_centrality(G_u).values())\n","    bet_cent = list(nx.betweenness_centrality(G_u).values())\n","    clos_cent = list(nx.closeness_centrality(G_u).values())\n","\n","    return {'avg_degree_centrality': float(np.mean(deg_cent)),\n","            'avg_betweenness': float(np.mean(bet_cent)),\n","            'avg_closeness': float(np.mean(clos_cent))\n","    }\n","\n","# ---------------------------------------------------------------------\n","# 3. Small-world Sigma\n","# ---------------------------------------------------------------------\n","'''\n","Currently unused given extreme computational bottleneck\n","'''\n","# def sigma_small_world(G):\n","#     # opted for plug-and-play sigma calculation from NetworkX over first principals calculation\n","#     # niter and nrand parameter values lowered to decrease computation time\n","#     return nx.sigma(G, niter= 1, nrand= 1)\n","\n","\n","# ---------------------------------------------------------------------\n","# 4. Power-law Exponent\n","# ---------------------------------------------------------------------\n","# '''\n","# Previously made use of full graph (floaters included),\n","# floater culling may have changed functionaly slightly\n","# '''\n","# def power_law_exponent(G):\n","#     degrees = [d for _, d in G.degree()]\n","#     fit = powerlaw.Fit(degrees, discrete=True, verbose=False)\n","#     return {\n","#         'pl_alpha': round(fit.power_law.alpha, 3),\n","#         'pl_xmin': fit.power_law.xmin\n","#         }\n","\n","# ---------------------------------------------------------------------\n","# 5. Pedigree Width\n","# ---------------------------------------------------------------------\n","def pedigree_width(G: nx.DiGraph) -> int:\n","    if not nx.is_directed_acyclic_graph(G):\n","        raise ValueError(\"Graph must be a DAG.\")\n","    #transitive closure creates new graph including all origianl edges and adding edges between all nodes connected by a path\n","    #i.e. for AD pedigree adds 4 edges connecting both grandparents to both of their grandchildren\n","    P = nx.algorithms.dag.transitive_closure(G)\n","    left  = {f\"{n}_L\" for n in G}\n","    right = {f\"{n}_R\" for n in G}\n","    B = nx.DiGraph()\n","    B.add_nodes_from(left,  bipartite=0)\n","    B.add_nodes_from(right, bipartite=1)\n","    for u, v in P.edges:\n","        B.add_edge(f\"{u}_L\", f\"{v}_R\")\n","    match = nx.algorithms.bipartite.maximum_matching(B, top_nodes=left)\n","    matched = len(match) // 2\n","    width = G.number_of_nodes() - matched\n","    return width\n","\n","# ---------------------------------------------------------------------\n","# 6. Transitive Reduction Size\n","# ---------------------------------------------------------------------\n","# How does transitive reduction work with our pedigrees?\n","# nx.transitive_reduction only returns a list of duples for edges in transitive reduction\n","# would only cull child-parent relationships in cases of consanguinity between partent and other child\n","def dict_transitive_reduction_size(G):\n","    red = nx.transitive_reduction(G)\n","    return {'TR_n_edges': red.number_of_edges(),\n","            'TR_edge_ratio': red.number_of_edges()/G.number_of_edges()}\n","\n","# ---------------------------------------------------------------------\n","# 7. Longest Path Length\n","# ---------------------------------------------------------------------\n","def longest_path_length(G):\n","    return nx.dag_longest_path_length(G)\n","\n","# ---------------------------------------------------------------------\n","# 8. Minimal Founder Coverage\n","# ---------------------------------------------------------------------\n","def minimal_founder_cover_set(G: nx.DiGraph) -> set:\n","    \"\"\"\n","    Return one minimal founder cover (greedy) as a Python set.\n","    \"\"\"\n","    #different founder condition than used in score enhancement (no stipulation on genotype)\n","    founders = [n for n in G if G.in_degree(n) == 0]\n","    cover, uncovered = set(), set(G.nodes)\n","    while uncovered:\n","        best = max(founders, key=lambda f: len(nx.descendants(G, f) & uncovered) + (f in uncovered))\n","        cover.add(best)\n","        uncovered -= nx.descendants(G, best)\n","        uncovered.discard(best)\n","    return cover\n","\n","def minimal_founder_coverage_size(G: nx.DiGraph) -> float:\n","    \"\"\"\n","    Return the size of the minimal founder coverage set.\n","    \"\"\"\n","    return len(minimal_founder_cover_set(G))\n","\n","# ---------------------------------------------------------------------\n","# 9. Founder Influence\n","# ---------------------------------------------------------------------\n","def founder_influence(G) -> Dict[str, float]:\n","    phen = nx.get_node_attributes(G, \"phenotype\")\n","    affected = {n for n, p in phen.items() if p == 2}\n","    memo_all, memo_aff = {}, {}\n","    def paths(u, memo, target=None):\n","        key = (u, id(target))\n","        if key in memo: return memo[key]\n","        total = 1 if target is None or u in target else 0\n","        for v in G.successors(u):\n","            total += paths(v, memo, target)\n","        memo[key] = total\n","        return total\n","    infl = {}\n","    for f in (n for n in G if G.in_degree(n)==0):\n","        all_p = paths(f, memo_all, None)\n","        aff_p = paths(f, memo_aff, affected)\n","        infl[f] = aff_p / all_p if all_p else 0\n","    return infl\n","\n","\n","# ---------------------------------------------------------------------\n","# GRAPH METRICS WRAPPER\n","# ---------------------------------------------------------------------\n","def graph_metrics(G):\n","    metrics = {**basic_graph_metrics(G), **centralities(G), **dict_transitive_reduction_size(G)}\n","    #metrics = {**metrics, **power_law_exponent(G)}\n","    #metrics['sigma_small_world'] = sigma_small_world(G)\n","    metrics['width'] = pedigree_width(G)\n","    metrics['longest_path'] = longest_path_length(G)\n","    metrics['founder_cover_size'] = minimal_founder_coverage_size(G)\n","    metrics['founder_influence'] = founder_influence(G)\n","\n","    return metrics\n","\n"],"metadata":{"id":"1mTWCGcRjR_7","executionInfo":{"status":"ok","timestamp":1752749183037,"user_tz":-60,"elapsed":2,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["###Scoring Metrics"],"metadata":{"id":"kYcXKMyuwj22"}},{"cell_type":"code","source":["#################### MODULAR VARIANT SCORING ####################\n","'''\n","Scores: measures of variant association likelihoods accounting for graph/pedigree structure as well as genotype and phenotype data,\n","provided in mode agnostic form\n","\n","Current List of Scores:\n","-------------------------\n","\n","'''\n","#----------------------------------------------------------------------\n","# 1v2. Edge Consistency\n","#----------------------------------------------------------------------\n","def edge_consistency(G, gt):\n","    \"\"\"\n","    Fraction of parent→child edges whose genotype transition is Mendelian-\n","    compatible under the specified inheritance mode.\n","    gt is a dict {node: 0/1/2}.\n","\n","    Given working off of genotypes, mode is irrelevant.\n","    \"\"\"\n","    #partental genotype (pg,mg) | (mg,pg) --> possible child genotypes {}\n","    BOTH_PARENT_ALLOWED_INHERITENCE = {\n","        (0,0):{0}, (1,0):{0,1}, (1,1):{0,1,2}, (2,1):{1,2}, (2,0):{1}, (2,2):{2}\n","    }\n","    SINGLE_PARENT_ALLOWED_INHERITENCE = {\n","        0:{0,1}, 1:{0,1,2}, 2:{1,2}\n","    }\n","    good=0; total=0\n","    for child in G:\n","        prnts=parents(G,child)\n","        if len(prnts) == 1:\n","            if gt[child] in SINGLE_PARENT_ALLOWED_INHERITENCE[gt[prnts[0]]]:\n","                good+=1\n","        elif len(prnts) == 2:\n","            gp,gm=[gt[p] for p in prnts]\n","            par_gt = (gp,gm) if (gp,gm) in BOTH_PARENT_ALLOWED_INHERITENCE.keys() else (gm,gp)\n","            if gt[child] in BOTH_PARENT_ALLOWED_INHERITENCE[par_gt]:\n","                good+=2\n","        total+= len(prnts)\n","    return good/total\n","\n","# ---------------------------------------------------------------------\n","# 2. Generation Continuity\n","# ---------------------------------------------------------------------\n","def generation_continuity(G, gt):\n","    \"\"\"\n","    Return the fraction of generations with carriers (by genotype)\n","    \"\"\"\n","    gen = generations(G)\n","    gens_total = max(gen.values())+1\n","    alt_gens = {gen[n] for n in G if gt[n]>0}\n","    return len(alt_gens)/gens_total if alt_gens else 0\n","\n","\n","\n","# ---------------------------------------------------------------------\n","# 3v2. Betweeness of Carriers in Affected+Carrier Subgraph\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","def carrier_betweenness(G, gt):\n","    aff_nodes = aff(G)\n","    unaff_nodes = unaff(G)\n","    carrier_nodes = [n for n in unaff_nodes if gt[n] == 1]\n","    carrier_aff_subgraph = G.subgraph(aff_nodes+carrier_nodes)\n","    subgraph_bet = nx.betweenness_centrality(carrier_aff_subgraph, normalized= False)\n","    complete_bet = nx.betweenness_centrality(G, normalized= False)\n","    avg_carrier_betweenness = np.mean([subgraph_bet[n] for n in carrier_aff_subgraph.nodes]) if len(carrier_nodes) > 0 else 0\n","    avg_complete_betweenness = np.mean([complete_bet[n] for n in G.nodes]) if len(G.nodes) > 0 else 0\n","\n","    adj_carrier_betweenness = avg_carrier_betweenness/avg_complete_betweenness if avg_complete_betweenness else 0\n","\n","    return adj_carrier_betweenness\n","\n","\n","# ---------------------------------------------------------------------\n","# VARIANT SCORING WRAPPER\n","# ---------------------------------------------------------------------\n","'''\n","Mode agnostics raw variant scores\n","'''\n","def variant_scores(G, gt):\n","    return {\n","        'edge_consistency': edge_consistency(G, gt),\n","        'generation_continuity': generation_continuity(G, gt),\n","        'carrier_betweenness': carrier_betweenness(G, gt)\n","    }"],"metadata":{"id":"qLmo24Mgsnfs","executionInfo":{"status":"ok","timestamp":1752749183065,"user_tz":-60,"elapsed":19,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["#IV. Pedigree and Variant Table Simulation"],"metadata":{"id":"xtetVhqEYLt-"}},{"cell_type":"code","source":["def pedigree_generator(max_children, FamilyID, mode, generation_count, alt_freq, AffectedSpouse= False, BackpropLikelihood= False):\n","        #-------------------------------------------\n","        # Helper Functions for Pedigree Propigation\n","        #-------------------------------------------\n","\n","        '''\n","        Basic helper function to add new entry to pedigree dataframe\n","        '''\n","        def entry_generator(IndividualID, PaternalID, MaternalID, Sex, Phenotype, Genotype):\n","            nonlocal family_df\n","            family_df.loc[IndividualID] = [FamilyID, PaternalID, MaternalID, Sex, Phenotype, Genotype]\n","\n","        '''\n","        Helper function to translate between genotype and phenotype\n","        Dependant on the mode of inheritance\n","        Input: genotype(int(0,1,2))\n","        Output: phenotype(int(1,2))\n","        '''\n","        def genotype_interpreter(genotype):\n","            if mode == 'AR':\n","                phenotype = 2 if genotype == 2 else 1\n","            if mode == 'AD':\n","                phenotype = 2 if genotype == 2 or genotype == 1 else 1\n","            return phenotype\n","\n","        def calc_inheritance_weights(p,q):\n","\n","            tt = q**4\n","            to = 2*p*(q**3)\n","            tz = (p**2)*(q**2)\n","            oo = 4*(p**2)*(q**2)\n","            oz = 2*(p**3)*(q)\n","            zz = p**4\n","\n","            homoRef = p**2\n","            hetero = 2*p*q\n","            homoAlt = q**2\n","\n","            inheritance_patterns = {\n","                'forward_genotypes': {\n","                #(paternal genotype, maternal genotype) -> [possible child genotypes]\n","                    (2,2): [2],\n","                    (2,1): [2,1],\n","                    (1,2): [2,1],\n","                    (2,0): [1],\n","                    (0,2): [1],\n","                    (1,1): [2,1,0],\n","                    (0,1): [1,0],\n","                    (1,0): [1,0],\n","                    (0,0): [0]\n","                },\n","                'forward_weights': {\n","                    (2,2): [1],\n","                    (2,1): [1,1],\n","                    (1,2): [1,1],\n","                    (2,0): [1],\n","                    (0,2): [1],\n","                    (1,1): [1,2,1],\n","                    (0,1): [1,1],\n","                    (1,0): [1,1],\n","                    (0,0): [1]\n","                },\n","                #child genotype -> [possible (paternal,maternal) genotypes]\n","                'reverse_genotypes': {\n","                    2: [(2,2),(2,1),(1,2),(1,1)],\n","                    1: [(2,1),(1,2),(2,0),(0,2),(1,1),(1,0),(0,1)],\n","                    0: [(1,0),(0,1),(0,0)]\n","                },\n","                'reverse_weights': {\n","                    2: [homoAlt**2, homoAlt*hetero, hetero*homoAlt, hetero**2],\n","                    1: [homoAlt*hetero, hetero*homoAlt, homoAlt*homoRef, homoRef*homoAlt, hetero**2, hetero*homoRef, homoRef*hetero],\n","                    0: [hetero*homoRef, homoRef*hetero, homoRef**2]\n","                }\n","            }\n","\n","            return inheritance_patterns\n","\n","        '''\n","        Wrapper function that generates the primary founder of the pedigree\n","        By default, this individual is affected\n","        If AD, 20% chance homozygous, 80% chance heterozygous.\n","        If AR, 100% chance homozygous.\n","        Input:\n","        Output:\n","        '''\n","        def primary_founder_generator():\n","            nonlocal family_df\n","\n","            if mode == 'AD':\n","                Genotype = random.choices(population= [1,2],\n","                                          weights= (0.8, 0.2))[0]\n","            elif mode == 'AR':\n","                Genotype= 2\n","\n","            entry_generator(IndividualID= 1,\n","                            PaternalID= 0,\n","                            MaternalID= 0,\n","                            Sex= random.randint(1,2),\n","                            Phenotype= 2,\n","                            Genotype= Genotype)\n","        '''\n","        Wrapper function that generates spouses unrelated to primary founder\n","        Spouse sex dependent on the relative of primary founder.\n","        Genotype and phenotype dependent on the mode of inheritance and affected spouse paramter.\n","        Input: relativeID(int)\n","        Ouput: n/a\n","        '''\n","        def spouse_generator(RelativeAnchorID):\n","            nonlocal family_df, alt_freq, ref_freq\n","\n","            pp = ref_freq**2\n","            pq2 = 2*ref_freq*alt_freq\n","            qq = alt_freq**2\n","\n","            Sex= 1 if family_df.loc[RelativeAnchorID]['Sex'] == 2 else 2\n","\n","            if AffectedSpouse:\n","                Genotype= random.choices(population= [0,1,2],\n","                                          weights= (pp, pq2, qq),\n","                                          k=1)[0]\n","\n","            else:\n","                Genotype = 0\n","\n","            entry_generator(IndividualID= len(family_df)+1,\n","                            PaternalID= 0,\n","                            MaternalID= 0,\n","                            Sex= Sex,\n","                            Phenotype= genotype_interpreter(Genotype),\n","                            Genotype= Genotype)\n","        '''\n","        Wrapper function that generates an entry for the child of two given individuals.\n","        Child's genotype is chosen from list of allowed gentypes given parents genotypes with equal likelihood.\n","        Input: PaternalID(int), MaternalID(int)\n","        Output: n/a\n","        '''\n","        def child_generator(PaternalID, MaternalID):\n","            nonlocal family_df, inheritance_patterns\n","\n","            parentalGenotype = (int(family_df.loc[PaternalID]['Genotype']), int(family_df.loc[MaternalID]['Genotype']))\n","\n","            Genotype = random.choices(population= inheritance_patterns['forward_genotypes'][parentalGenotype],\n","                                      weights= inheritance_patterns['forward_weights'][parentalGenotype],\n","                                      k=1)[0]\n","\n","            entry_generator(IndividualID= len(family_df)+1,\n","                            PaternalID= PaternalID,\n","                            MaternalID= MaternalID,\n","                            Sex= random.randint(1,2),\n","                            Phenotype= genotype_interpreter(Genotype),\n","                            Genotype= Genotype)\n","        #---------------------------------------\n","        # Primary Pedigree Contruction Functions\n","        #---------------------------------------\n","        '''\n","        Function that recursively constructs pedigree in backward direction.\n","        Infers ancestors of individuals unrelated to primary founder as they are added.\n","        Input: current_generation(int), RealativeAnchorID(int)\n","        Output: n/a\n","        '''\n","        def recursive_history_backprop(current_generation, RelativeAnchorID):\n","            nonlocal family_df, generation_count, inheritance_patterns, BackpropLikelihood\n","\n","            BackpropRNG = random.randint(1,100)/100\n","\n","            if current_generation > 0 and BackpropRNG <= BackpropLikelihood:\n","\n","                GenotypeTup = random.choices(population= inheritance_patterns['reverse_genotypes'][family_df.loc[RelativeAnchorID]['Genotype']],\n","                                                    weights= inheritance_patterns['reverse_weights'][family_df.loc[RelativeAnchorID]['Genotype']],\n","                                                    k=1)[0]\n","\n","                ID_list = ['PaternalID', 'MaternalID']\n","\n","                for i in range(2):\n","                    entry_generator(IndividualID= len(family_df)+1,\n","                                    PaternalID= 0,\n","                                    MaternalID= 0,\n","                                    Sex= 1 + i,\n","                                    Phenotype= genotype_interpreter(GenotypeTup[i]),\n","                                    Genotype= GenotypeTup[i])\n","                    family_df.at[RelativeAnchorID, ID_list[i]] = len(family_df)\n","                    recursive_history_backprop(current_generation-1, len(family_df))\n","\n","        '''\n","        Function that recursively constructs pedigree in forward direction.\n","        Input: current_generation(int), RelativeAnchorID(int)\n","        Output: n/a\n","        '''\n","        def recursive_pedigree_construction(current_generation, RelativeAnchorID):\n","            nonlocal family_df, max_children, generation_count\n","\n","            if current_generation < generation_count-1:\n","\n","                spouse_generator(RelativeAnchorID= RelativeAnchorID)\n","\n","                #Determining Parental Sex for next generation\n","                if family_df.loc[RelativeAnchorID]['Sex'] == 1:\n","                    PaternalID = RelativeAnchorID\n","                    MaternalID = len(family_df)\n","                else:\n","                    PaternalID = len(family_df)\n","                    MaternalID = RelativeAnchorID\n","\n","                if BackpropLikelihood:\n","                    recursive_history_backprop(current_generation, len(family_df))\n","\n","                for child in range(random.randint(1, max_children)):\n","                    child_generator(PaternalID= PaternalID, MaternalID= MaternalID)\n","                    recursive_pedigree_construction(current_generation+1, len(family_df))\n","\n","\n","        #-------------------------------------\n","        # 1. Construct the empty data frame\n","        #-------------------------------------\n","        pedigree_construction_columns = ['FamilyID', 'IndividualID', 'PaternalID', 'MaternalID', 'Sex', 'Phenotype', 'Genotype']\n","        family_df = pd.DataFrame(columns= pedigree_construction_columns)\n","        family_df.set_index('IndividualID', inplace=True)\n","\n","        #-------------------------------------\n","        # 2. Generating Primary Founder\n","        #-------------------------------------\n","        primary_founder_generator()\n","\n","        #--------------------------------------------\n","        # 3. Construct Inheritence Pattern Dictionary\n","        #--------------------------------------------\n","        ref_freq = 1 - alt_freq\n","        inheritance_patterns = calc_inheritance_weights(ref_freq, alt_freq)\n","\n","        #----------------------------------------\n","        # 4. Generating Pedigree\n","        #----------------------------------------\n","        recursive_pedigree_construction(current_generation= 0, RelativeAnchorID= 1)\n","\n","        #-------------------------------\n","        # 5. Resetign Standard Indexing\n","        #-------------------------------\n","        family_df.reset_index(inplace= True)\n","\n","        return family_df"],"metadata":{"id":"3M3mRkOlYRIs","executionInfo":{"status":"ok","timestamp":1752749183117,"user_tz":-60,"elapsed":53,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def simulate_variant_table(G, mode='AD', n_bg=5, linked_variant_gt_skeleton = False):\n","    samples = list(G.nodes)\n","    phen = nx.get_node_attributes(G,'phenotype')\n","    vars = {}\n","    # causal\n","    causal = 'chr1:100000_A>T'\n","    if linked_variant_gt_skeleton:\n","        vars[causal] = linked_variant_gt_skeleton\n","    else:\n","        gt = {s:0 for s in samples}\n","        any_affected = [n for n in samples if phen[n]==2]\n","        for n in any_affected:\n","            gt[n] = 1 if mode == 'AD' else 2 if mode == 'AR' else 0\n","            if mode == 'AR':\n","                chldrn = children(G,n)\n","                for c in chldrn:\n","                    if c not in any_affected:\n","                        gt[c] = 1\n","        vars[causal]=gt\n","    # background\n","    for i in range(n_bg):\n","        vid=f'chr1:{100200+i}_G>C'\n","        vars[vid]={s:random.choices([0,1,2],[0.8,0.18,0.02])[0] for s in samples}\n","    return vars\n","\n","\n"],"metadata":{"id":"LK4mG_nUW7yE","executionInfo":{"status":"ok","timestamp":1752749183159,"user_tz":-60,"elapsed":41,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["from os import link\n","def pedigree_group_generator(pedigree_count, mode, max_children, generation_count, n_bg= 5, alt_freq = 0, simple_gt= True):\n","    Fam_Data_Dict = {}\n","    for Family_Num in range(1, pedigree_count+1):\n","        FamilyID = f'FAM{Family_Num}'\n","\n","        #for cases in which alt_frequency is not given (defaults are mode-dependent)\n","        if not alt_freq:\n","          alt_freq = random.randint(2,8)/100 if mode == 'AD' else random.randint(5,20)/100\n","\n","        QC_checks = 0\n","        QC_pass = False\n","        while not QC_pass:\n","            QC_checks += 1\n","            ped_df = pedigree_generator(max_children= max_children,\n","                                        FamilyID= FamilyID,\n","                                        mode= mode,\n","                                        generation_count= generation_count,\n","                                        alt_freq= alt_freq,\n","                                        BackpropLikelihood= random.choice([0.25,0.5,0.75]),\n","                                        AffectedSpouse= True)\n","            ped_dg = construct_pedigree_graph(ped_df)\n","            affected_nodes = aff(ped_dg)\n","            if len(affected_nodes) > 1 and len(ped_dg.nodes()) >= (generation_count * 2):\n","                QC_pass = True\n","            elif QC_checks >= 25:\n","                print(f'{mode} {FamilyID}: Failed QC checks, included despite QC failure to prioritize futher operations')\n","                QC_pass = True\n","        linked_variant_gt_skeleton = {key: value for key, value in zip(ped_df['IndividualID'], ped_df['Genotype'])}\n","        for indv in linked_variant_gt_skeleton.keys():\n","            linked_variant_gt_skeleton[indv] = int(linked_variant_gt_skeleton[indv])\n","        var_dict = simulate_variant_table(G= ped_dg,\n","                                          mode= mode,\n","                                          n_bg= n_bg,\n","                                          linked_variant_gt_skeleton= linked_variant_gt_skeleton if simple_gt else False)\n","        Fam_Data_Dict[FamilyID] = {'PedGraph': ped_dg, 'VarTable': var_dict}\n","    return Fam_Data_Dict"],"metadata":{"id":"OCxKc2AtkgfE","executionInfo":{"status":"ok","timestamp":1752749183200,"user_tz":-60,"elapsed":41,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["ped_AD = '''\\\n","FAM1 1 0 0 1 2\n","FAM1 2 0 0 2 1\n","FAM1 3 1 2 1 2\n","FAM1 4 1 2 2 1\n","FAM1 5 0 0 2 1\n","FAM1 6 3 5 1 2\n","FAM1 7 3 5 2 1\n","FAM1 8 0 0 1 1\n","'''\n","open('ad_complete.ped','w').write(ped_AD)\n","\n","\n","ped_AR = '''\\\n","FAM2 1 0 0 1 1\n","FAM2 2 0 0 2 1\n","FAM2 3 1 2 1 1\n","FAM2 4 1 2 2 1\n","FAM2 10 0 0 1 1\n","FAM2 11 0 0 2 1\n","FAM2 5 3 11 1 2\n","FAM2 6 3 11 2 1\n","FAM2 7 4 10 2 2\n","FAM2 8 4 10 1 1\n","'''\n","open('ar_complete.ped','w').write(ped_AR)\n","\n","DF_ad = pedfile_readin('ad_complete.ped')\n","DF_ar = pedfile_readin('ar_complete.ped')\n","G_ad = construct_pedigree_graph(DF_ad)\n","G_ar = construct_pedigree_graph(DF_ar)"],"metadata":{"id":"BiGLM8TKeQ8a","executionInfo":{"status":"ok","timestamp":1752749183209,"user_tz":-60,"elapsed":10,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["vars_AD = simulate_variant_table(G_ad, 'AD')\n","vars_AR = simulate_variant_table(G_ar, 'AR')"],"metadata":{"id":"3Tk2NSUfeVD8","executionInfo":{"status":"ok","timestamp":1752749183252,"user_tz":-60,"elapsed":3,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["AD_Fam_Data = pedigree_group_generator(pedigree_count= 100,\n","                                       mode= 'AD',\n","                                       max_children= 3,\n","                                       generation_count= 3,\n","                                       n_bg= 9,\n","                                       simple_gt = True)\n","AR_Fam_Data = pedigree_group_generator(pedigree_count= 100,\n","                                       mode= 'AR',\n","                                       max_children= 3,\n","                                       generation_count= 3,\n","                                       n_bg= 9,\n","                                       simple_gt = True)"],"metadata":{"id":"B57GEisQTpe2","executionInfo":{"status":"ok","timestamp":1752750135745,"user_tz":-60,"elapsed":9867,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":["#V. Mode of Inheritence Classification"],"metadata":{"id":"YZ_NP-9adN_O"}},{"cell_type":"code","source":["def trial_based_feature_threshold_determination(generation_count,\n","                                                trial_count=1000,\n","                                                max_children= 3,\n","                                                AD_alt_freq_range= (2,10),\n","                                                AR_alt_freq_range= (5,20),\n","                                                verbose = True,\n","                                                size_agnostic = False,\n","                                                accuracy_threshold = 0.7):\n","    '''\n","    Determines optimal inheritence pattern determination thresholds for pedigrees of given generation count\n","    based on a given number of randomly generated trial pedigrees\n","    '''\n","\n","    def trial_pedigree_generation():\n","        nonlocal generation_count, trial_count, AD_alt_freq_range, AR_alt_freq_range, max_children, size_agnostic\n","\n","        all_trial_pedigree_features = pd.DataFrame()\n","\n","        for trialID in range(1, trial_count+1):\n","            famID = 'TestFam' + str(trialID)\n","            actual_mode = random.choice(['AD', 'AR'])\n","            alt_freq_min = AD_alt_freq_range[0] if actual_mode == 'AD' else AR_alt_freq_range[0]\n","            alt_freq_max = AD_alt_freq_range[1] if actual_mode == 'AD' else AR_alt_freq_range[1]\n","            alt_freq = random.randint(alt_freq_min, alt_freq_max)/100\n","\n","            #Accounting for cases where we want thresholds that are not specific to a generation count\n","            if size_agnostic:\n","                #Run time seems to increase indefinitely if left to be size_agnostic so currently unusable feature\n","                trial_generation_count = random.randint(2, generation_count)\n","            else:\n","                trial_generation_count = generation_count\n","\n","            QC_pass = False\n","            while not QC_pass:\n","                trial_pedigree_df = pedigree_generator(FamilyID= famID,\n","                                                       mode= actual_mode,\n","                                                       max_children= random.randint(2,max_children),\n","                                                       generation_count= trial_generation_count,\n","                                                       AffectedSpouse= True,\n","                                                       BackpropLikelihood= random.choice([0.25, 0.5, 0.75]),\n","                                                       alt_freq= alt_freq)\n","                trial_pedigree_dg = construct_pedigree_graph(trial_pedigree_df)\n","\n","                affecteded_nodes = aff(trial_pedigree_dg)\n","                if len(affecteded_nodes) > 1 and len(trial_pedigree_dg.nodes()) > (generation_count * 2) - 1:\n","                    QC_pass = True\n","\n","\n","            trial_feat_met_dict = {**pedigree_features(trial_pedigree_dg), **graph_metrics(trial_pedigree_dg), **{'actual_mode': actual_mode}}\n","            trial_feat_met_df = pd.DataFrame(trial_feat_met_dict, index= [0])\n","\n","            all_trial_pedigree_features = pd.concat(objs= [all_trial_pedigree_features, trial_feat_met_df], ignore_index=True)\n","\n","        return all_trial_pedigree_features\n","\n","\n","\n","\n","    def ROC_param_calc(true_labels, predicted_labels):\n","        real_pos_count = 0\n","        real_neg_count = 0\n","        true_pos_count = 0\n","        false_pos_count = 0\n","\n","        for i in range(len(true_labels)):\n","            if true_labels[i] == 'AD':\n","                real_pos_count += 1\n","                if predicted_labels[i] == 'AD':\n","                    true_pos_count += 1\n","            elif true_labels[i] == 'AR':\n","                real_neg_count += 1\n","                if predicted_labels[i] == 'AD':\n","                    false_pos_count += 1\n","\n","\n","        TPR = true_pos_count/real_pos_count\n","        FPR = false_pos_count/real_neg_count\n","\n","        return TPR, FPR\n","\n","    def AUC_calc(FPR_scores, TPR_scores):\n","        FPR_arr = np.array(FPR_scores)\n","        TPR_arr = np.array(TPR_scores)\n","\n","        sort_indx = np.argsort(FPR_arr)\n","        FPR_arr = FPR_arr[sort_indx]\n","        TPR_arr = TPR_arr[sort_indx]\n","\n","        auc_score = auc(FPR_arr, TPR_arr)\n","\n","        return auc_score\n","\n","    def ROC_plot(features, TPR_score_dict, FPR_score_dict):\n","\n","        fig = plt.figure()\n","        ax = plt.subplot(111)\n","\n","        for feature in features:\n","            AUC_score = AUC_calc(FPR_scores= FPR_score_dict[feature],\n","                                 TPR_scores= TPR_score_dict[feature])\n","            ax.plot(FPR_score_dict[feature], TPR_score_dict[feature],\n","                    label= f'{feature} = {AUC_score:.2f}')\n","\n","        ax.plot([0,1], [0,1], linestyle='--', color='gray')\n","        ax.set_xlabel('False Positive Rate')\n","        ax.set_ylabel('True Positive Rate')\n","        ax.set_title(f'Mode of Inheritance ROC')\n","        ax.grid(True)\n","\n","        box= ax.get_position()\n","        ax.set_position([box.x0, box.y0, box.width*0.8, box.height])\n","        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n","                  ncol= 2, fancybox=True, shadow=True)\n","\n","\n","    def single_feature_threshold_determination(feature_values, actual_mode_labels):\n","        min_value = min(feature_values)\n","        max_value = max(feature_values)\n","        thresh_increment = (max_value - min_value)/100\n","        min_value = min_value - thresh_increment\n","        threshold_options = [min_value+(thresh_increment*i) for i in range(103)]\n","\n","        best_threshold = None\n","        best_accuracy = 0\n","        best_direction = None\n","\n","        #Test accuracy of each threshold (both as upper and lower limit of AD classification) and store accuracy score\n","        TPR_scores = []\n","        FPR_scores = []\n","        for threshold in threshold_options:\n","            greater_equal_predictions = ['AD' if value > threshold else 'AR' for value in feature_values]\n","            less_predictions = ['AD' if value <= threshold else 'AR' for value in feature_values]\n","\n","            greater_equal_accuracy = accuracy_score(actual_mode_labels, greater_equal_predictions)\n","            less_accuracy = accuracy_score(actual_mode_labels, less_predictions)\n","\n","            if greater_equal_accuracy > best_accuracy:\n","                best_accuracy = greater_equal_accuracy\n","                best_threshold = threshold\n","                best_direction = 'greater'\n","            elif less_accuracy > best_accuracy:\n","                best_accuracy = less_accuracy\n","                best_threshold = threshold\n","                best_direction = 'less_equal'\n","\n","            TPR, FPR = ROC_param_calc(actual_mode_labels, greater_equal_predictions)\n","            TPR_scores.append(TPR)\n","            FPR_scores.append(FPR)\n","\n","        return best_threshold, best_direction, best_accuracy, TPR_scores, FPR_scores\n","\n","    accuracy_checks = 0\n","    max_accuracy_checks = 3\n","    accuracy_QC_pass = False\n","    while not accuracy_QC_pass and accuracy_checks < max_accuracy_checks:\n","        accuracy_checks += 1\n","        trial_features_df = trial_pedigree_generation()\n","        training_features_df = trial_features_df.sample(frac=0.8)\n","        testing_features_df = trial_features_df.drop(training_features_df.index)\n","\n","\n","\n","        TPR_scores_dict = {}\n","        FPR_scores_dict = {}\n","        thresholds_dict = {}\n","        for feature in trial_features_df.columns.values:\n","            if feature == 'FamID' or feature == 'actual_mode':\n","                continue\n","            threshold, direction, accuracy, TPR_scores, FPR_scores = single_feature_threshold_determination(training_features_df[feature].values,\n","                                                                                                            training_features_df['actual_mode'].values)\n","            thresholds_dict[feature] = {'threshold': threshold, 'direction': direction, 'accuracy': accuracy}\n","            TPR_scores_dict[feature] = TPR_scores\n","            FPR_scores_dict[feature] = FPR_scores\n","\n","        mode_prediction_field = []\n","        for _,row in testing_features_df.iterrows():\n","            predicted_mode = inheritance_pattern_classification(row,\n","                                                                thresholds_dict = thresholds_dict)\n","            mode_prediction_field.append(predicted_mode)\n","        testing_features_df['predicted_mode'] = mode_prediction_field\n","\n","        overall_classification_accuracy = accuracy_score(y_true= testing_features_df['actual_mode'],\n","                                                         y_pred= testing_features_df['predicted_mode'])\n","\n","        certain_test_results_df = testing_features_df[testing_features_df['predicted_mode']!='Uncertain']\n","        num_certain_results = len(certain_test_results_df)\n","        certain_classification_accuracy = accuracy_score(y_true= certain_test_results_df['actual_mode'],\n","                                                         y_pred= certain_test_results_df['predicted_mode'])\n","\n","        if certain_classification_accuracy >= accuracy_threshold and num_certain_results/len(testing_features_df) >= accuracy_threshold:\n","            accuracy_QC_pass = True\n","\n","\n","\n","    if verbose:\n","        ROC_plot(features= thresholds_dict.keys(),\n","                 TPR_score_dict= TPR_scores_dict,\n","                 FPR_score_dict= FPR_scores_dict)\n","        print(f'Number of Certain Results: {num_certain_results}/{len(testing_features_df)}')\n","        print(f'Certain Classification Accuracy: {certain_classification_accuracy}')\n","        print(f'Overall Classification Accuracy: {overall_classification_accuracy}')\n","\n","    return thresholds_dict\n","\n","def inheritance_pattern_classification(sample_features,\n","                                       thresholds_dict,\n","                                       min_accuracy_score= 0.7) -> str:\n","\n","    votes= 0\n","    total= 0\n","    for feature, descriptors in thresholds_dict.items():\n","        threshold = descriptors['threshold']\n","        direction = descriptors['direction']\n","        accuracy = descriptors['accuracy']\n","        feature_value = sample_features[feature]\n","\n","        if accuracy >= min_accuracy_score:\n","            total += 1\n","            if direction == 'greater':\n","                if feature_value > threshold:\n","                    votes += 1\n","            elif direction == 'less_equal':\n","                if feature_value <= threshold:\n","                    votes += 1\n","\n","    if total == 0:\n","        return 'Uncertain'\n","    elif votes/total > 0.75:\n","        return 'AD'\n","    elif votes/total < 0.25:\n","        return 'AR'\n","    else:\n","        return 'Uncertain'\n"],"metadata":{"id":"lVVvhnvoaOvo","executionInfo":{"status":"ok","timestamp":1752749305025,"user_tz":-60,"elapsed":71,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["def classify_pedigree(G, thresholds_dict= 0) -> str:\n","    if isinstance(G, nx.DiGraph):\n","        if not thresholds_dict:\n","            thresholds_dict = trial_based_feature_threshold_determination(generation_count= max(generations(G).values())+1)\n","        pedigree_feats_mets = {**pedigree_features(G), **graph_metrics(G)}\n","    else:\n","        raise TypeError(f'Invalid Input Type: classify pedigree takes NetworkX directed graph with optional thresholds dict as input; given {type(G)}')\n","\n","    return inheritance_pattern_classification(sample_features= pedigree_feats_mets,\n","                                              thresholds_dict= thresholds_dict)"],"metadata":{"id":"CEMxXPZ6qZUs","executionInfo":{"status":"ok","timestamp":1752749305039,"user_tz":-60,"elapsed":7,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["def classify_multiple_pedigrees(Multi_Ped_Dict: dict, thresholds_dict= 0, same_size= True):\n","    if same_size:\n","        if not thresholds_dict:\n","            threshold_basis_graph = random.choice(list(Multi_Ped_Dict.values()))['PedGraph']\n","            thresholds_dict = trial_based_feature_threshold_determination(generation_count= max(generations(threshold_basis_graph).values())+1)\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            G = Multi_Ped_Dict[FamilyID]['PedGraph']\n","            Multi_Ped_Dict[FamilyID]['pred_mode'] = classify_pedigree(G, thresholds_dict= thresholds_dict)\n","    return Multi_Ped_Dict\n","\n","    # else:\n","    #     print('To be implemented later: classification of heterogeniously sized pedigrees')"],"metadata":{"id":"xGja9Ffeqc-b","executionInfo":{"status":"ok","timestamp":1752749305106,"user_tz":-60,"elapsed":66,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def pedigree_group_mode_agreement(Multi_Ped_Dict: dict):\n","    '''\n","    Returns the mutliple pedigree data file with updated predicted modes as well as the\n","    most prevelant inheritance mode classification found in the predicted modes\n","    '''\n","    Multi_Ped_Dict = classify_multiple_pedigrees(Multi_Ped_Dict)\n","    mode_lst = [Multi_Ped_Dict[FamilyID]['pred_mode'] for FamilyID in Multi_Ped_Dict.keys()]\n","    agreed_mode = max(set(mode_lst), key= mode_lst.count)\n","    return Multi_Ped_Dict, agreed_mode"],"metadata":{"id":"dZROSDvkqhi1","executionInfo":{"status":"ok","timestamp":1752749305106,"user_tz":-60,"elapsed":3,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["#VI. Segregation Scoring"],"metadata":{"id":"Yo9kqW91WuaV"}},{"cell_type":"code","execution_count":52,"metadata":{"id":"JZgbS-EoDHvy","executionInfo":{"status":"ok","timestamp":1752749305249,"user_tz":-60,"elapsed":144,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def segregation_network_score(G, gt, mode, Scoring_Method= 'Original', weights={'w_edge':.6,'w_gen':0.2,'w_bet':0.2}, verbose= False):\n","\n","    # edge score does not depend on mode??? gt inheritenc patter is the same regardless\n","    # shouldn't all variants follow mendelian pattern barring mutational event\n","    # made new edge consistency that looks at parental genotype and child phenotype pairings\n","    edge_score= edge_consistency(G,gt)\n","\n","    # generation continuity\n","    gen_score= generation_continuity(G,gt)\n","    #Why are we reversing this for AR (wouldnt we also expect this to close to 1 for AR variants as well)???\n","    #this pattern seems to apply more to phenotype patterns not genotype\n","    # if mode=='AR':\n","    #     gen_score= 1-gen_score\n","    gen_score= max(0,min(1,gen_score)) #ensures genscore within [0,1]\n","\n","    # carrier betweenness\n","    cb = carrier_betweenness(G, gt)\n","    bet_score= cb if mode=='AR' else 1-cb\n","    bet_score= max(0,min(1,bet_score))\n","\n","\n","\n","\n","\n","    if Scoring_Method == 'Extended':\n","        if len(weights.keys()) < 5:\n","            weights = {'w_edge': 0.2, 'w_gen': 0.2, 'w_bet': 0.2, 'w_found': 0.2, 'w_depth': 0.2}\n","        #average founders influence\n","        founders = [n for n in G if G.in_degree(n)==0 and gt[n]>0]\n","        if founders:\n","            fi = founder_influence(G)\n","            found_score = sum(fi[f] for f in founders) / len(founders)\n","        else:\n","            found_score = 0\n","\n","        #redundancy score\n","        red_score = edge_consistency(nx.transitive_reduction(G), gt)\n","\n","        #depth score\n","        depth = longest_path_length(G)\n","        alt_nodes = [n for n in G if gt[n]>0]\n","        alt_depth = 0\n","        if depth and founders and alt_nodes:\n","            # shortest founder→alt path for each pair that is connected\n","            lengths = []\n","            for f in founders:\n","                for a in alt_nodes:\n","                    if nx.has_path(G, f, a):\n","                        lengths.append(nx.shortest_path_length(G, f, a))\n","            if lengths:\n","                alt_depth = max(lengths)\n","        depth_score = alt_depth / depth\n","\n","        #width score\n","        width_score = pedigree_width(G) / 4\n","\n","        #coverage score\n","        cover = minimal_founder_cover_set(G)\n","        cov_score = 0\n","\n","        score = (weights['w_edge'] * edge_score) + (weights['w_gen'] * gen_score) + (weights['w_bet'] * bet_score)\n","        score += (weights['w_found'] * found_score) + (weights['w_depth'] * depth_score)\n","\n","\n","    else:\n","        score = (weights['w_edge'] * edge_score) + (weights['w_gen'] * gen_score) + (weights['w_bet'] * bet_score)\n","\n","    '''\n","    Current Scoring Metrics:\n","        Original:\n","            edge_score\n","            gen_score\n","            bet_score\n","        Extended:\n","            found_score\n","            red_score (CURRENTLY UNUSED)\n","            depth_score\n","            width_score (CURRENTLY UNUSED)\n","            cov_score (CURRENTLY UNUSED)\n","    '''\n","    if verbose:\n","        print(f'Edge Score: {edge_score}; Gen Score: {gen_score}; Bet Score: {bet_score}')\n","        if Scoring_Method == 'Extended':\n","            print(f'Found Score: {found_score}; Depth Score: {depth_score}')\n","        print(f'Segregation Score: {score}')\n","    return score\n","\n","def original_scan_variants(G, vars_dict, weights, mode='AD'):\n","    # mode= classify_pedigree(G)\n","    w_edge, w_gen, w_bet = weights\n","    scores={vid: segregation_network_score(G,gt,mode,w_edge, w_gen, w_bet) for vid,gt in vars_dict.items()}\n","    best=max(scores,key=scores.get)\n","    return best, scores\n"]},{"cell_type":"markdown","source":["Scoring Helper Functions"],"metadata":{"id":"nihCElu5AR0F"}},{"cell_type":"code","source":["def max_score_highlighter(s):\n","    is_max = s == s.max()\n","    return [\n","        'background-color: green' if max_score and varID == 'chr1:100000_A>T'\n","        else 'background-color: red' if max_score\n","        else ''\n","        for varID, max_score in zip(s.index, is_max)]"],"metadata":{"id":"5P5K52lqAP28","executionInfo":{"status":"ok","timestamp":1752749305250,"user_tz":-60,"elapsed":3,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["def pprint_weights(weights_dict):\n","    for weight_name, weight_value in weights_dict.items():\n","        weight_value = round(weight_value, 3)\n","        print(f'{weight_name}: {weight_value}')\n","    print()"],"metadata":{"id":"pbJVknj6B-Ye","executionInfo":{"status":"ok","timestamp":1752750517338,"user_tz":-60,"elapsed":28,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["Weights Optimization"],"metadata":{"id":"HjPwmZdTet7Q"}},{"cell_type":"code","source":["#Margin Objective Function\n","def margin_weight_optimization_objective(weights_lst, Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode):\n","\n","    weights_dict = {weight_names[i]: weights_lst[i] for i in range(len(weight_names))}\n","    margins = []\n","    for FamilyID, FamilyData in Multi_Ped_Dict.items():\n","        G, VarTable = FamilyData['PedGraph'], FamilyData['VarTable']\n","        linked_score = segregation_network_score(G= G,\n","                                                 gt= VarTable[linked_variant],\n","                                                 mode= mode,\n","                                                 Scoring_Method= Scoring_Method,\n","                                                 weights= weights_dict)\n","\n","        unlinked_scores = []\n","        for VarID, gt in VarTable.items():\n","            if VarID != linked_variant:\n","                unlinked_scores.append(segregation_network_score(G= G,\n","                                      gt= VarTable[VarID],\n","                                      mode= mode,\n","                                      Scoring_Method= Scoring_Method,\n","                                      weights= weights_dict))\n","        max_unlinked_score = max(unlinked_scores)\n","\n","        margin = linked_score - max_unlinked_score\n","        margins.append(margin)\n","\n","    avg_margin = np.mean(margins)\n","\n","    return 1 - avg_margin\n","\n","\n","#Fraction Objective Function\n","def fraction_weight_optimization_objective(weights_lst, Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode):\n","\n","    weights_dict = {weight_names[i]: weights_lst[i] for i in range(len(weight_names))}\n","    correct = 0\n","    total = 0\n","    margins = []\n","    for FamilyID, FamilyData in Multi_Ped_Dict.items():\n","        G, VarTable = FamilyData['PedGraph'], FamilyData['VarTable']\n","        linked_score = segregation_network_score(G= G,\n","                                                 gt= VarTable[linked_variant],\n","                                                 mode= mode,\n","                                                 Scoring_Method= Scoring_Method,\n","                                                 weights= weights_dict)\n","\n","        unlinked_scores = []\n","        for VarID, gt in VarTable.items():\n","            if VarID != linked_variant:\n","                unlinked_scores.append(segregation_network_score(G= G,\n","                                      gt= VarTable[VarID],\n","                                      mode= mode,\n","                                      Scoring_Method= Scoring_Method,\n","                                      weights= weights_dict))\n","\n","        max_unlinked_score = max(unlinked_scores)\n","\n","        margin = linked_score - max_unlinked_score\n","        if margin > 0:\n","            margin = margin * 1.5\n","        margins.append(margin)\n","\n","\n","\n","    avg_margin = np.mean(margins)\n","\n","\n","    return 1 - avg_margin\n","\n","\n","#Optimization Wrapper\n","def weights_optimization(Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, Optimization_Method, mode= 'AD'):\n","    n_weights = len(weight_names)\n","    bounds = [(0.001,1)]*n_weights\n","    constraints = {'type': 'eq',\n","                  #figure out how this function is working\n","                  'fun': lambda w: np.sum(w)-1}\n","    initial_guess = np.array([1/n_weights]*n_weights)\n","\n","    if Optimization_Method == 'Margin':\n","        results = minimize(fun= margin_weight_optimization_objective,\n","                          x0= initial_guess,\n","                          args= (Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode),\n","                          bounds= bounds,\n","                          constraints= constraints)\n","    elif Optimization_Method == 'Fraction':\n","        results = minimize(fun= fraction_weight_optimization_objective,\n","                          x0= initial_guess,\n","                          args= (Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode),\n","                          bounds= bounds,\n","                          constraints= constraints)\n","\n","    #Directly attaching weights with their names as dictionary for ease of use is scoring wrapper function\n","    optimized_weights = {weight_names[i]: results.x[i] for i in range(len(weight_names))}\n","\n","    return optimized_weights"],"metadata":{"id":"YAOqvAgiewgS","executionInfo":{"status":"ok","timestamp":1752749305313,"user_tz":-60,"elapsed":65,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["def segregation_scoring_wrapper(Multi_Ped_Dict: dict,\n","                                Scoring_Method= 'Original',\n","                                weights= 0,\n","                                Optimization_Method= 'None',\n","                                Verbose= True,\n","                                Known_Linked_Var= False,\n","                                Known_Mode= 0):\n","    '''\n","    Takes multi-pedigree data dictionaries as input and outputs the dictionary with updated scores\n","    '''\n","    if not Known_Mode:\n","        Multi_Ped_Dict, agreed_mode = pedigree_group_mode_agreement(Multi_Ped_Dict)\n","    else:\n","        agreed_mode = Known_Mode\n","\n","    if Scoring_Method == 'Original':\n","        weight_names = ['w_edge', 'w_gen', 'w_bet']\n","    elif Scoring_Method == 'Extended':\n","        weight_names = ['w_edge', 'w_gen', 'w_bet', 'w_found', 'w_depth']\n","\n","    #manually assignment of weights if no weights given if using original scoring\n","    if not weights:\n","        if Optimization_Method == 'None':\n","            if Scoring_Method == 'Original':\n","                weights= {\n","                    'w_edge': 0.6,\n","                    'w_gen': 0.2,\n","                    'w_bet': 0.2\n","                }\n","            elif Scoring_Method == 'Extended':\n","                weights= {\n","                    'w_edge': 0.125,\n","                    'w_gen': 0.125,\n","                    'w_bet': 0.125,\n","                    'w_found': 0.125,\n","                    'w_red': 0.125,\n","                    'w_depth': 0.125,\n","                    'w_width': 0.125,\n","                    'w_cov': 0.125\n","                }\n","            print(f'Default {Scoring_Method} Weights:')\n","\n","        elif Optimization_Method == 'Margin' or Optimization_Method == 'Fraction':\n","            training_Multi_Ped_Dict = {}\n","            test_Multi_Ped_Dict = {}\n","            tt_split = 0.8\n","            for FamilyID in Multi_Ped_Dict.keys():\n","                if int(FamilyID[3:]) <= int(tt_split*len(Multi_Ped_Dict)):\n","                    training_Multi_Ped_Dict[FamilyID] = Multi_Ped_Dict[FamilyID]\n","                else:\n","                    test_Multi_Ped_Dict[FamilyID] = Multi_Ped_Dict[FamilyID]\n","            #Downsize the original multiple pedigree dict to the testing data now that we have done training testing split\n","            Multi_Ped_Dict = test_Multi_Ped_Dict\n","            weights= weights_optimization(Multi_Ped_Dict= training_Multi_Ped_Dict,\n","                                                linked_variant= Known_Linked_Var,\n","                                                weight_names= weight_names,\n","                                                Scoring_Method= Scoring_Method,\n","                                                Optimization_Method= Optimization_Method,\n","                                                mode= agreed_mode)\n","            print(f'{Optimization_Method} Optimized {Scoring_Method} Weights:')\n","\n","\n","        else:\n","            raise NotImplementedError\n","\n","    else:\n","        print(f'Given {Scoring_Method} Weights:')\n","\n","    pprint_weights(weights)\n","\n","\n","    All_Family_Score_df = pd.DataFrame(columns=Multi_Ped_Dict.keys())\n","    for FamilyID in Multi_Ped_Dict.keys():\n","        PedGraph, VarTable = Multi_Ped_Dict[FamilyID]['PedGraph'], Multi_Ped_Dict[FamilyID]['VarTable']\n","        if not Known_Mode:\n","            pred_mode = Multi_Ped_Dict[FamilyID]['pred_mode']\n","        else:\n","            pred_mode = Known_Mode\n","\n","        #convert uncertain classified pedigrees to AD (can change scoring to accomodate later)\n","        #currently using agreed mode for scoring parameter so should not matter\n","        if pred_mode == 'Uncertain':\n","           pred_mode = 'AD'\n","\n","        Multi_Ped_Dict[FamilyID][Scoring_Method] = {\n","                            VarID: segregation_network_score(G= PedGraph,\n","                                                              gt= VarTable[VarID],\n","                                                              mode= agreed_mode,\n","                                                              Scoring_Method= Scoring_Method,\n","                                                              weights= weights)\n","                            for VarID in VarTable.keys()}\n","\n","        All_Family_Score_df[FamilyID] = Multi_Ped_Dict[FamilyID][Scoring_Method]\n","\n","    if Known_Linked_Var:\n","        Correctly_Scored_Pedigrees = 0\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            if max(Multi_Ped_Dict[FamilyID][Scoring_Method], key= Multi_Ped_Dict[FamilyID][Scoring_Method].get) == Known_Linked_Var:\n","                Correctly_Scored_Pedigrees += 1\n","        Scoring_Method_Accuracy = Correctly_Scored_Pedigrees/len(Multi_Ped_Dict)\n","\n","    #displaying scores if verbose option chosen\n","    if Verbose:\n","        #printing dataframe with highest scoring variant highlighted for each family\n","        print(f'{Scoring_Method} Segregation Scoring Results')\n","        styled_All_Family_Score_df = All_Family_Score_df.style.apply(max_score_highlighter, axis=0)\n","        display(styled_All_Family_Score_df)\n","        print(f'{Scoring_Method} Segregation Scoring Accuracy: {Scoring_Method_Accuracy}')\n","\n","\n","\n","    return Multi_Ped_Dict, weights, Scoring_Method_Accuracy\n","\n"],"metadata":{"id":"MWp9RgLyvoKr","executionInfo":{"status":"ok","timestamp":1752750099607,"user_tz":-60,"elapsed":24,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["def segregation_scoring_performance_test(Multi_Ped_Dict,\n","                                         Known_Mode= False,\n","                                         Known_Linked_Var= 'chr1:100000_A>T',\n","                                         Verbose= False,\n","                                         VarScore_Readout= False):\n","    Scoring_Modes = ['Original', 'Extended']\n","    Optimization_Methods = ['None', 'Margin', 'Fraction']\n","\n","    if not Known_Mode:\n","        Multi_Ped_Dict, Known_Mode = pedigree_group_mode_agreement(Multi_Ped_Dict)\n","\n","    scoring_performance_results_dict = {\n","                                          'Optimization Method': Optimization_Methods,\n","                                          'Original': [],\n","                                          'Extended': []\n","                                        }\n","    for scoring_mode in Scoring_Modes:\n","        for optimization_method in Optimization_Methods:\n","            _, _, scoring_perfomance = segregation_scoring_wrapper(Multi_Ped_Dict= Multi_Ped_Dict,\n","                                                                    Scoring_Method= scoring_mode,\n","                                                                    Optimization_Method= optimization_method,\n","                                                                    Verbose= VarScore_Readout,\n","                                                                    Known_Linked_Var= Known_Linked_Var,\n","                                                                    Known_Mode= Known_Mode)\n","            scoring_performance_results_dict[scoring_mode].append(scoring_perfomance)\n","\n","    scoring_performance_results_df = pd.DataFrame.from_dict(scoring_performance_results_dict).set_index('Optimization Method')\n","\n","    if Verbose:\n","        print(f'{Known_Mode} Scoring Performance Results')\n","        display(scoring_performance_results_df)\n","\n","    #return scoring_performance_results_df"],"metadata":{"id":"glI-QdfUncWv","executionInfo":{"status":"ok","timestamp":1752750623761,"user_tz":-60,"elapsed":4,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["segregation_scoring_performance_test(Multi_Ped_Dict= AD_Fam_Data,\n","                                     Known_Mode= 'AD',\n","                                     Verbose= True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":838},"id":"lAHkq1NtAPeO","executionInfo":{"status":"ok","timestamp":1752751344047,"user_tz":-60,"elapsed":400791,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"b7ff5f61-daad-4ce8-8095-96ccd074a36b"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Margin Optimized Original Weights:\n","w_edge: 0.303\n","w_gen: 0.302\n","w_bet: 0.395\n","\n","Fraction Optimized Original Weights:\n","w_edge: 0.303\n","w_gen: 0.303\n","w_bet: 0.394\n","\n","Default Extended Weights:\n","w_edge: 0.125\n","w_gen: 0.125\n","w_bet: 0.125\n","w_found: 0.125\n","w_red: 0.125\n","w_depth: 0.125\n","w_width: 0.125\n","w_cov: 0.125\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.189\n","w_gen: 0.142\n","w_bet: 0.458\n","w_found: 0.126\n","w_depth: 0.085\n","\n","Fraction Optimized Extended Weights:\n","w_edge: 0.188\n","w_gen: 0.143\n","w_bet: 0.463\n","w_found: 0.111\n","w_depth: 0.095\n","\n","AD Scoring Performance Results\n"]},{"output_type":"display_data","data":{"text/plain":["  Optimization Method  Original  Extended\n","0                None      0.97      0.88\n","1              Margin      1.00      1.00\n","2            Fraction      1.00      1.00"],"text/html":["\n","  <div id=\"df-feaf6f8b-17a0-4523-a1f9-fc77b348b0b0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Optimization Method</th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>None</td>\n","      <td>0.97</td>\n","      <td>0.88</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Margin</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fraction</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feaf6f8b-17a0-4523-a1f9-fc77b348b0b0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-feaf6f8b-17a0-4523-a1f9-fc77b348b0b0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-feaf6f8b-17a0-4523-a1f9-fc77b348b0b0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-993d5ef9-d28d-4577-9fa6-50776836a561\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-993d5ef9-d28d-4577-9fa6-50776836a561')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-993d5ef9-d28d-4577-9fa6-50776836a561 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                                     Verbose= True)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Optimization Method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None\",\n          \"Margin\",\n          \"Fraction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01732050807568879,\n        \"min\": 0.97,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06928203230275509,\n        \"min\": 0.88,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["segregation_scoring_performance_test(Multi_Ped_Dict= AR_Fam_Data,\n","                                     Known_Mode= 'AR',\n","                                     Verbose= True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":838},"id":"KUHvYTOvFIBt","executionInfo":{"status":"ok","timestamp":1752750943245,"user_tz":-60,"elapsed":240760,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"dc3692f3-5a57-4eb6-e48f-e2ff6a1aa78a"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Margin Optimized Original Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.998\n","\n","Fraction Optimized Original Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.998\n","\n","Default Extended Weights:\n","w_edge: 0.125\n","w_gen: 0.125\n","w_bet: 0.125\n","w_found: 0.125\n","w_red: 0.125\n","w_depth: 0.125\n","w_width: 0.125\n","w_cov: 0.125\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.903\n","w_found: 0.001\n","w_depth: 0.094\n","\n","Fraction Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.928\n","w_found: 0.001\n","w_depth: 0.069\n","\n","AR Scoring Performance Results\n"]},{"output_type":"display_data","data":{"text/plain":["  Optimization Method  Original  Extended\n","0                None      0.96      0.97\n","1              Margin      0.95      0.95\n","2            Fraction      0.95      0.95"],"text/html":["\n","  <div id=\"df-2938f21a-92a6-4179-9a67-c952eab947a5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Optimization Method</th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>None</td>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Margin</td>\n","      <td>0.95</td>\n","      <td>0.95</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fraction</td>\n","      <td>0.95</td>\n","      <td>0.95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2938f21a-92a6-4179-9a67-c952eab947a5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2938f21a-92a6-4179-9a67-c952eab947a5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2938f21a-92a6-4179-9a67-c952eab947a5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-debf59cb-842a-41d0-b1b9-652480c8449f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-debf59cb-842a-41d0-b1b9-652480c8449f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-debf59cb-842a-41d0-b1b9-652480c8449f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                                     Verbose= True)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Optimization Method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None\",\n          \"Margin\",\n          \"Fraction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005773502691896262,\n        \"min\": 0.95,\n        \"max\": 0.96,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.95,\n          0.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011547005383792525,\n        \"min\": 0.95,\n        \"max\": 0.97,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.95,\n          0.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["#Pedigree Size and Scoring Performance"],"metadata":{"id":"Zf41qMcnjTNi"}},{"cell_type":"code","source":["def pedigree_size_performance_test(Generation_Range,\n","                                   Pedigree_Count,\n","                                   Variant_Count,\n","                                   Optimization_Method,\n","                                   Mode,\n","                                   max_children= 3,\n","                                   Known_Linked_Var= 'chr1:100000_A>T',\n","                                   Verbose= False):\n","    pedigree_size_scroing_results_dict = {\n","        'Pedigree Size': [],\n","        'Original': [],\n","        'Extended': []\n","    }\n","    min_gen = Generation_Range[0]\n","    max_gen = Generation_Range[1]\n","    for i in range(min_gen, max_gen+1):\n","        pedigree_size_scroing_results_dict['Pedigree Size'].append(i)\n","\n","    for Gen_Count in range(min_gen, max_gen+1):\n","        Fam_Data = pedigree_group_generator(pedigree_count= Pedigree_Count,\n","                                            generation_count= Gen_Count,\n","                                            max_children= max_children,\n","                                            n_bg= Variant_Count-1,\n","                                            mode= Mode,\n","                                            simple_gt= True)\n","        print(f'GENERATION COUNT= {Gen_Count} ')\n","        for Scoring_Method in ['Original', 'Extended']:\n","            _, _, Scoring_Accuracy = segregation_scoring_wrapper(Multi_Ped_Dict= Fam_Data,\n","                                                                  Scoring_Method= Scoring_Method,\n","                                                                  Optimization_Method= Optimization_Method,\n","                                                                  Known_Linked_Var= Known_Linked_Var,\n","                                                                  Known_Mode= Mode,\n","                                                                  Verbose= False)\n","            pedigree_size_scroing_results_dict[Scoring_Method].append(Scoring_Accuracy)\n","        print()\n","    pedigree_size_scroing_results_df = pd.DataFrame.from_dict(pedigree_size_scroing_results_dict).set_index('Pedigree Size')\n","    if Verbose:\n","        if Optimization_Method == 'None':\n","            print(f'{Mode} Pedigree Unoptimized Size Scoring Results')\n","        else:\n","            print(f'{Mode} Pedigree {Optimization_Method} Optimized Size Scoring Results')\n","        display(pedigree_size_scroing_results_df)\n","\n","    #return pedigree_size_scroing_results_df"],"metadata":{"id":"zAIlfuBJHbvI","executionInfo":{"status":"ok","timestamp":1752754461099,"user_tz":-60,"elapsed":26,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["pedigree_size_performance_test(Generation_Range= (3,5),\n","                               Pedigree_Count= 50,\n","                               Variant_Count= 10,\n","                               Optimization_Method= 'Margin',\n","                               Mode= 'AD',\n","                               Verbose= True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":921},"id":"h4xujoMOMxGe","executionInfo":{"status":"ok","timestamp":1752754461065,"user_tz":-60,"elapsed":1315294,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"85537d68-512b-41c5-945d-af006ed39aea"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights Generation Count 3 \n","Margin Optimized Original Weights:\n","w_edge: 0.261\n","w_gen: 0.37\n","w_bet: 0.37\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.159\n","w_gen: 0.161\n","w_bet: 0.42\n","w_found: 0.092\n","w_depth: 0.168\n","\n","\n","Weights Generation Count 4 \n","Margin Optimized Original Weights:\n","w_edge: 0.186\n","w_gen: 0.037\n","w_bet: 0.777\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.26\n","w_gen: 0.025\n","w_bet: 0.569\n","w_found: 0.123\n","w_depth: 0.023\n","\n","\n","Weights Generation Count 5 \n","Margin Optimized Original Weights:\n","w_edge: 0.003\n","w_gen: 0.001\n","w_bet: 0.996\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.683\n","w_found: 0.314\n","w_depth: 0.001\n","\n","\n","AD Pedigree Size Scoring Results\n"]},{"output_type":"display_data","data":{"text/plain":["               Original  Extended\n","Pedigree Size                    \n","3                   0.9       0.9\n","4                   0.9       1.0\n","5                   0.9       1.0"],"text/html":["\n","  <div id=\"df-ada81a31-ea5f-4214-8376-edb84040fefc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","    <tr>\n","      <th>Pedigree Size</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9</td>\n","      <td>0.9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.9</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ada81a31-ea5f-4214-8376-edb84040fefc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ada81a31-ea5f-4214-8376-edb84040fefc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ada81a31-ea5f-4214-8376-edb84040fefc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-941a0c4a-4226-4adc-97b2-374188923b2c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-941a0c4a-4226-4adc-97b2-374188923b2c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-941a0c4a-4226-4adc-97b2-374188923b2c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                               Verbose= True)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Pedigree Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9,\n        \"max\": 0.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05773502691896256,\n        \"min\": 0.9,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["#**Notes:**\n","*   Removing floaters helped increase differentiation in AD raw score rankings\n","*   Majority of enhanced scoring metrics are unhelpful for classification according to margin maximization efforts\n","*   Changes to betweeness scoring to work off affected and carrier subgraph greatly improved scoring (including mode dependent scoring)\n","*   Fraction based optimization showing the faults in margin based optimization (maybe need to work off of something other than average of margin, add additional boolean gate??)\n","    *  Fraction based optimization does not seem to be acutalually varying the weights and sticking with defaults.\n","      * turns out this is because the fraction is not a smooth function and has large plataues, the minimization function relies on this function being smooth and coninuous with a clear gradient for minimzation\n","    *  Should try penalizing the cases where the incorrect varient recieves the highest score (-1 penality to average margin?) where correctly scored variants have normal margin calculation\n","      * adjusted the fraction optimization to have -0.5 penalty when incorrectly scored (working to mixed results, both optimization techniques range wildly in their efficacy)\n","    *  Optimized weights are consistently under performing compared to default weights for AR scoring, extended scoring providing some benefit (currently doing additive 1.5 bonus for margins that are correctly scored in fraction optimization)\n","*   Added testing/training split for cases of weight optimization\n","*   Adjusted betweeness scores:\n","    * network X normalizes scores by default\n","    * previous was scoring carrier betweeness by doing average carrier normalized score for carrier+affected subgraph\n","    * trialed doing subgraph betweeness(avg)/complete betweeness(avg) with both scores being the normalized scores: this resulted in many score values > 1\n","    * tried same scoring metric without normalization: worked well, many scores went to default 0 or 1 but work towards the trends we want for scoring\n"],"metadata":{"id":"Hx1sS4fQ80RZ"}},{"cell_type":"markdown","source":["#Testbed"],"metadata":{"id":"jtIyHxUSLlqN"}},{"cell_type":"markdown","source":["Transverse Reduction"],"metadata":{"id":"kxskRlZdLpC3"}},{"cell_type":"code","source":["testG_AD = copy.deepcopy(G_ad)\n","testG_AD.add_node(8, family='FAM1', sex=1, phenotype=2)\n","testG_AD.add_edge(1, 8)\n","testG_AD.add_edge(4, 8)\n","\n","test_trG_AD = nx.transitive_reduction(testG_AD)\n","test_trG_AD.add_nodes_from(testG_AD.nodes(data=True))\n","test_trG_AD.add_edges_from((u, v, testG_AD.edges[u,v]) for u, v in test_trG_AD.edges)\n","\n","plot_pedigree_tree(testG_AD, title=\"Consanguinous Addition (AD)\")\n","plot_pedigree_tree(test_trG_AD, title=\"Transitive Reduction Consaguinous Addtion (AD)\")\n","\n","\n","trG_AD = nx.transitive_reduction(G_ad)\n","trG_AD.add_nodes_from(G_ad.nodes(data=True))\n","trG_AD.add_edges_from((u, v, G_ad.edges[u,v]) for u, v in trG_AD.edges)\n","\n","plot_pedigree_tree(G_ad, title=\"Original (AD)\")\n","plot_pedigree_tree(trG_AD, title=\"Transitive Reduction (AD)\")\n","\n","pprint(dag_summary(G_ad))"],"metadata":{"id":"I2gAy0Fc7HEM","executionInfo":{"status":"aborted","timestamp":1752749305566,"user_tz":-60,"elapsed":148874,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------------------\n","# 1v1. Original Edge Consistency Scoring\n","# ---------------------------------------------------------------------\n","def old_edge_consistency(G, gt, mode=\"AD\"):\n","    \"\"\"\n","    Fraction of parent→child edges whose genotype transition is Mendelian-\n","    compatible under the specified inheritance mode.\n","    gt is a dict {node: 0/1/2}.\n","    \"\"\"\n","    ALLOWED_INHERITENCE = {\n","        'AD': {(0,0):{0}, (1,0):{0,1}, (0,1):{0,1}, (1,1):{0,1,2}, (2,_):{1,2}},\n","        'AR': {(0,0):{0}, (1,0):{0,1}, (0,1):{0,1}, (1,1):{0,1,2}, (2,_):{1,2}},\n","    }\n","    good=0; total=0\n","    for child in G:\n","        prnts=parents(G,child)\n","        gp,gm=[gt.get(p,0) for p in prnts+[0,0]][:2]\n","        par_gt = (gp,gm) if (gp,gm) in ALLOWED_INHERITENCE[mode] else (gm,gp)\n","        par_gt = (2,_) if par_gt not in ALLOWED_INHERITENCE[mode] else par_gt\n","        if gt[child] in ALLOWED_INHERITENCE[mode][par_gt]:\n","            good+=1\n","        total+=1\n","    return good/total"],"metadata":{"id":"ajr33NUmTU4P","executionInfo":{"status":"aborted","timestamp":1752749305567,"user_tz":-60,"elapsed":148875,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------------------\n","# 3v1. Carrier Betweeness\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct so as to trial subgraph version that prunes graph to affected nodes and carriers\n","'''\n","def old_carrier_betweenness(G, gt):\n","    phen = nx.get_node_attributes(G, \"phenotype\")\n","    het_car=[n for n in G if gt[n]==1 and phen[n]!=2]\n","\n","    if het_car:\n","        bet = nx.betweenness_centrality(G)\n","        cb = sum(bet[n] for n in het_car)/len(het_car)\n","        cb /= max(bet.values()) if bet else 1\n","        return cb\n","    else:\n","        return 0"],"metadata":{"id":"kqUhge2sTpUW","executionInfo":{"status":"aborted","timestamp":1752749305568,"user_tz":-60,"elapsed":148876,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]}]}
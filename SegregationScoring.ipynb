{"cells":[{"cell_type":"markdown","metadata":{"id":"KBxiRyiFWqXw"},"source":["#I. Machine Prep"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62488,"status":"ok","timestamp":1755352906143,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"TnHmewk_LcCf","outputId":"7adc76a6-75dc-4e1e-dbf2-b96cc2a1259b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","graphviz is already the newest version (2.42.2-6ubuntu0.1).\n","The following additional packages will be installed:\n","  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n","  libgvc6-plugins-gtk librsvg2-common libxdot4\n","Suggested packages:\n","  gvfs\n","The following NEW packages will be installed:\n","  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n","  libgtk2.0-common libgvc6-plugins-gtk librsvg2-common libxdot4\n","0 upgraded, 9 newly installed, 0 to remove and 35 not upgraded.\n","Need to get 2,434 kB of archives.\n","After this operation, 7,681 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libxdot4 amd64 2.42.2-6ubuntu0.1 [16.4 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6ubuntu0.1 [22.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgraphviz-dev amd64 2.42.2-6ubuntu0.1 [58.5 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n","Fetched 2,434 kB in 6s (396 kB/s)\n","Selecting previously unselected package libgtk2.0-common.\n","(Reading database ... 126380 files and directories currently installed.)\n","Preparing to unpack .../0-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n","Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgtk2.0-0:amd64.\n","Preparing to unpack .../1-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgail18:amd64.\n","Preparing to unpack .../2-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libgail-common:amd64.\n","Preparing to unpack .../3-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package libxdot4:amd64.\n","Preparing to unpack .../4-libxdot4_2.42.2-6ubuntu0.1_amd64.deb ...\n","Unpacking libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n","Selecting previously unselected package libgvc6-plugins-gtk.\n","Preparing to unpack .../5-libgvc6-plugins-gtk_2.42.2-6ubuntu0.1_amd64.deb ...\n","Unpacking libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n","Selecting previously unselected package libgraphviz-dev:amd64.\n","Preparing to unpack .../6-libgraphviz-dev_2.42.2-6ubuntu0.1_amd64.deb ...\n","Unpacking libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n","Selecting previously unselected package libgtk2.0-bin.\n","Preparing to unpack .../7-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n","Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n","Selecting previously unselected package librsvg2-common:amd64.\n","Preparing to unpack .../8-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n","Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n","Setting up libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n","Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n","Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n","Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n","Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n","Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n","Setting up libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n","Collecting pygraphviz\n","  Downloading pygraphviz-1.14.tar.gz (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m727.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pygraphviz\n","  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp311-cp311-linux_x86_64.whl size=169716 sha256=fa00d9863bb03a3f0ee209741ed359a96ba8e7c0690615c18c5e002a0daeca5c\n","  Stored in directory: /root/.cache/pip/wheels/9c/5f/df/6fffd2a4353f26dbb0e3672a1baf070c124a1d74a5f9318279\n","Successfully built pygraphviz\n","Installing collected packages: pygraphviz\n","Successfully installed pygraphviz-1.14\n","Collecting powerlaw\n","  Downloading powerlaw-1.5-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from powerlaw) (1.16.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from powerlaw) (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from powerlaw) (3.10.0)\n","Requirement already satisfied: mpmath in /usr/local/lib/python3.11/dist-packages (from powerlaw) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->powerlaw) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->powerlaw) (1.17.0)\n","Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n","Installing collected packages: powerlaw\n","Successfully installed powerlaw-1.5\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n"]}],"source":["%pip install pandas\n","!apt install graphviz libgraphviz-dev\n","%pip install pygraphviz\n","%pip install powerlaw\n","%pip install networkx"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3527,"status":"ok","timestamp":1755352909667,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"Kdpq9BulYHKk"},"outputs":[],"source":["import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from sklearn.metrics import accuracy_score, auc\n","import pprint\n","import numpy as np\n","from collections import OrderedDict\n","import powerlaw\n","import itertools as it\n","from typing import Dict, Set, Tuple\n","from scipy.optimize import minimize\n","import copy\n","from pprint import pprint"]},{"cell_type":"markdown","metadata":{"id":"U3iisDMaYWZj"},"source":["#II. Pedigree Graph Conversion"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1755352909694,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"6sV8J9aiYa5w"},"outputs":[],"source":["def pedfile_readin(pedfile):\n","    cols = ['FamilyID', 'IndividualID', 'PaternalID', 'MaternalID', 'Sex', 'Phenotype']\n","    df = pd.read_csv(pedfile, sep=r'\\s+', header=None, names=cols)\n","    return df\n","\n","\n","def construct_pedigree_graph(df, rm_floaters= True):\n","    G = nx.DiGraph()\n","\n","    all_parents_set = set()\n","    founder_set = set()\n","\n","    for _, row in df.iterrows():\n","        # Make sure IndividualID is treated as a string or int consistently if needed\n","        G.add_node(row['IndividualID'],\n","                  family=row['FamilyID'],\n","                  sex=row['Sex'],\n","                  phenotype=row['Phenotype'])\n","\n","    for _, row in df.iterrows():\n","        # Ensure PaternalID and MaternalID are compared to string '0' if they are strings\n","        paternal_id = row['PaternalID']\n","        maternal_id = row['MaternalID']\n","        individual_id = row['IndividualID']\n","\n","        if paternal_id != 0:\n","            G.add_edge(paternal_id, individual_id)\n","            all_parents_set.add(paternal_id)\n","        if maternal_id != 0:\n","            G.add_edge(maternal_id, individual_id)\n","            all_parents_set.add(maternal_id)\n","        if maternal_id == 0 and paternal_id == 0:\n","            founder_set.add(individual_id)\n","\n","    #Removing founders with no children (i.e. floaters)\n","    if rm_floaters:\n","        floaters_set = founder_set - all_parents_set\n","        G.remove_nodes_from(floaters_set)\n","\n","\n","    return G"]},{"cell_type":"markdown","metadata":{"id":"qFh3pZrXYjCq"},"source":["###Pedigree Graph Visualization"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1755352909721,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"r0R4dLLLYmbk"},"outputs":[],"source":["def plot_pedigree_tree(G, title=\"Pedigree (Tree Layout)\"):\n","    try:\n","        from networkx.drawing.nx_agraph import graphviz_layout\n","        pos = graphviz_layout(G, prog='dot')  # 'dot' gives top-down DAG style\n","    except ImportError:\n","        print(\"PyGraphviz not installed. Falling back to spring layout.\")\n","        pos = nx.spring_layout(G, seed=42)\n","\n","    node_colors = ['red' if G.nodes[n]['phenotype'] == 2 else 'lightblue' for n in G.nodes]\n","\n","    nx.draw(G, pos, with_labels=True, node_color=node_colors, arrows=True)\n","    plt.title(title)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"wZuGOFdRabR1"},"source":["#III. Pedigree Graph Analysis"]},{"cell_type":"markdown","metadata":{"id":"IkjU5ec4asuu"},"source":["###Simple Pedigree Helper Functions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1755352909781,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"buKtIoswapHo"},"outputs":[],"source":["def parents(G, node):\n","    \"\"\"Return a list of parent nodes for `node` (incoming edges).\"\"\"\n","    return list(G.predecessors(node))\n","\n","def siblings(G, node):\n","    \"\"\"Return siblings: nodes that share ≥ 1 parent with `node`.\"\"\"\n","    sibs = set()\n","    for p in parents(G, node):\n","        sibs.update(G.successors(p))\n","    sibs.discard(node)\n","    return sibs\n","\n","def children(G, node):\n","    \"\"\"Return a list of child nodes for `node` (outgoing edges).\"\"\"\n","    return list(G.successors(node))\n","\n","def generations(G):\n","    lvl={}\n","    Q=[(n,0) for n in G if G.in_degree(n)==0]\n","    while Q:\n","        n,d=Q.pop(0)\n","        #this check doesnt take into account children produced from one founder and one relative\n","        #leads all individuals to have the generation count to be minimum distance from most recent founder\n","        #if n in lvl: continue\n","        lvl[n]=d\n","        for c in G.successors(n): Q.append((c,d+1))\n","    return lvl\n","\n","def aff(G):\n","    return [n for n in G.nodes if G.nodes[n]['phenotype']==2]\n","def unaff(G):\n","    return [n for n in G.nodes if G.nodes[n]['phenotype']==1]\n"]},{"cell_type":"markdown","metadata":{"id":"cvyvTNF7cfmc"},"source":["###Pedigree Feature Extraction and Metric Calculation"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1755352909830,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"qkY1ab3PcxCl"},"outputs":[],"source":["#################### MODULAR PEDIGREE FEATURES ####################\n","'''\n","Features: measures based on inheritence patterns gleaned from pedigree data alone,\n","no use of genotype or graph-specific data\n","\n","Current List of Features:\n","-------------------------\n","1. Ratio Affected Parents\n","2. Generation Coverage\n","3. Affected Sibling Clustering\n","4. Average Betweeness of Unaffected\n","5. Average Betweeness of Carriers (CURRENTLY EXCLUDED)\n","6. Average Betweeness of Carriers in Affected+Carrier Subgraph (CURRENTLY EXCLUDED)\n","'''\n","\n","# ---------------------------------------------------------------------\n","# 1. Ratio Affected Parents\n","# ---------------------------------------------------------------------\n","def ratio_aff_parents(G):\n","    aff_nodes = aff(G)\n","    aff_aff_partent = 0\n","    for n in aff_nodes:\n","        if any(G.nodes[p]['phenotype']==2 for p in parents(G,n)):\n","            aff_aff_partent +=1\n","    return aff_aff_partent/len(aff_nodes) if aff_nodes else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 2. Generation Coverage\n","# ---------------------------------------------------------------------\n","def gen_cov(G):\n","    gen = generations(G)\n","    gens_aff = {gen[n] for n in aff(G)}\n","    return len(gens_aff)/(max(gen.values())+1) if gen else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 3. Affected Sibling Clustering\n","# ---------------------------------------------------------------------\n","def sibling_aff_ratio(G):\n","    sib_pairs=0; aa_pairs=0\n","    for n in aff(G):\n","        for sib in siblings(G,n):\n","            if sib in aff(G):\n","                aa_pairs+=1\n","            sib_pairs+=1\n","    return aa_pairs/sib_pairs if sib_pairs else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 4. Average Betweeness of Unaffected\n","# ---------------------------------------------------------------------\n","def avg_bet_unaff(G):\n","    unaffecteds = unaff(G)\n","    bet = nx.betweenness_centrality(G)\n","    return np.mean([bet[n] for n in unaffecteds]) if unaffecteds else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 5. Average Betweeness of Carriers\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","# def avg_bet_carrier(G):\n","#     carriers = [n for n in unaff(G) if G.nodes[n]['phenotype'] == 1]\n","#     bet = nx.betweenness_centrality(G)\n","#     return np.mean([bet[n] for n in carriers]) if carriers else 0\n","\n","\n","# ---------------------------------------------------------------------\n","# 6. Average Betweeness of Carriers in Affected+Carrier Subgraph\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","# def avg_bet_carrier_subgraph(G):\n","#     aff_nodes = aff(G)\n","#     unaff_nodes = unaff(G)\n","#     carrier_nodes = [n for n in unaff_nodes if G.nodes[n]['genotype'] == 1]\n","#     bet = nx.betweenness_centrality(G.subgraph(aff_nodes+carrier_nodes))\n","#     return np.mean([bet[n] for n in carrier_nodes]) if carrier_nodes else 0\n","\n","\n","\n","# ---------------------------------------------------------------------\n","# PEDIGREE FEATURES WRAPPER\n","# ---------------------------------------------------------------------\n","def pedigree_features(G):\n","    return {\n","        'ratio_aff_parent': ratio_aff_parents(G),\n","        'gen_cov': gen_cov(G),\n","        'sibling_aff_ratio': sibling_aff_ratio(G),\n","        'avg_bet_unaff': avg_bet_unaff(G),\n","\n","        # See exclusion reasoning in function description above\n","        #'avg_bet_carrier': avg_bet_carrier(G),\n","        #'avg_bet_carrier_subgraph': avg_bet_carrier_subgraph(G)\n","    }\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1755352910074,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"1mTWCGcRjR_7"},"outputs":[],"source":["#################### MODULAR GRAPH METRICS ####################\n","'''\n","Metrics: measures based on network structure and phenotype data independent of genotype data\n","\n","Current List of Metrics:\n","-------------------------\n","1. Number of Nodes\n","2. Number of Edges\n","3. Number of Connected Components\n","4. Average Clustering Coefficient\n","5. Diameter\n","6. Average Shortest Path Length\n","7. Average Degree Centrality\n","8. Average Betweenness Centrality\n","9. Average Closeness Centrality\n","10. Power Law Alpha  (CURRENTLY EXCLUDED)\n","11. Power Law Xmin  (CURRENTLY EXCLUDED)\n","12. Sigma Small World (CURRENTLY EXCLUDED)\n","13. Pedigree Width\n","14. Number of Edges of Transitive Reduction\n","15. Transitive Reduction Size Ratio\n","16. Longest Path Length\n","17. Minimal Founder Coverage Size\n","18. Founder Influence\n","'''\n","\n","# ---------------------------------------------------------------------\n","# 1. Basic Graph Metrics\n","# ---------------------------------------------------------------------\n","def basic_graph_metrics(G):\n","    G_u = G.to_undirected()\n","    return {\n","        'n_nodes': G.number_of_nodes(),\n","        'n_edges': G.number_of_edges(),\n","        'n_components': nx.number_connected_components(G_u),\n","        'avg_clustering': nx.average_clustering(G_u),\n","        'diameter': nx.diameter(G_u),\n","        'avg_path_len': nx.average_shortest_path_length(G_u)\n","    }\n","\n","# ---------------------------------------------------------------------\n","# 2. Centralities\n","# ---------------------------------------------------------------------\n","def centralities(G):\n","    G_u = G.to_undirected()\n","    deg_cent = list(nx.degree_centrality(G_u).values())\n","    bet_cent = list(nx.betweenness_centrality(G_u).values())\n","    clos_cent = list(nx.closeness_centrality(G_u).values())\n","\n","    return {'avg_degree_centrality': float(np.mean(deg_cent)),\n","            'avg_betweenness': float(np.mean(bet_cent)),\n","            'avg_closeness': float(np.mean(clos_cent))\n","    }\n","\n","# ---------------------------------------------------------------------\n","# 3. Small-world Sigma\n","# ---------------------------------------------------------------------\n","'''\n","Currently unused given extreme computational bottleneck\n","'''\n","# def sigma_small_world(G):\n","#     # opted for plug-and-play sigma calculation from NetworkX over first principals calculation\n","#     # niter and nrand parameter values lowered to decrease computation time\n","#     return nx.sigma(G, niter= 1, nrand= 1)\n","\n","\n","# ---------------------------------------------------------------------\n","# 4. Power-law Exponent\n","# ---------------------------------------------------------------------\n","# '''\n","# Previously made use of full graph (floaters included),\n","# floater culling may have changed functionaly slightly\n","# '''\n","# def power_law_exponent(G):\n","#     degrees = [d for _, d in G.degree()]\n","#     fit = powerlaw.Fit(degrees, discrete=True, verbose=False)\n","#     return {\n","#         'pl_alpha': round(fit.power_law.alpha, 3),\n","#         'pl_xmin': fit.power_law.xmin\n","#         }\n","\n","# ---------------------------------------------------------------------\n","# 5. Pedigree Width\n","# ---------------------------------------------------------------------\n","def pedigree_width(G: nx.DiGraph) -> int:\n","    if not nx.is_directed_acyclic_graph(G):\n","        raise ValueError(\"Graph must be a DAG.\")\n","    #transitive closure creates new graph including all origianl edges and adding edges between all nodes connected by a path\n","    #i.e. for AD pedigree adds 4 edges connecting both grandparents to both of their grandchildren\n","    P = nx.algorithms.dag.transitive_closure(G)\n","    left  = {f\"{n}_L\" for n in G}\n","    right = {f\"{n}_R\" for n in G}\n","    B = nx.DiGraph()\n","    B.add_nodes_from(left,  bipartite=0)\n","    B.add_nodes_from(right, bipartite=1)\n","    for u, v in P.edges:\n","        B.add_edge(f\"{u}_L\", f\"{v}_R\")\n","    match = nx.algorithms.bipartite.maximum_matching(B, top_nodes=left) #finds maximum number of node pairing each connected by eges that maximizes the number of nodes included in the set (no repeats)\n","    # this match includes both directions (one pairing left-right (normal) and one pairing right-left (reverse))\n","    matched = len(match) // 2\n","    width = G.number_of_nodes() - matched\n","    return width\n","\n","# ---------------------------------------------------------------------\n","# 6. Transitive Reduction Size\n","# ---------------------------------------------------------------------\n","# How does transitive reduction work with our pedigrees?\n","# nx.transitive_reduction only returns a list of duples for edges in transitive reduction\n","# would only cull child-parent relationships in cases of consanguinity between partent and other child\n","def transitive_reduction_ratio(G):\n","    red = nx.transitive_reduction(G)\n","    return red.number_of_edges()/G.number_of_edges()\n","\n","# ---------------------------------------------------------------------\n","# 7. Longest Path Length\n","# ---------------------------------------------------------------------\n","def longest_path_length(G):\n","    return nx.dag_longest_path_length(G)\n","\n","# ---------------------------------------------------------------------\n","# 8. Minimal Founder Coverage\n","# ---------------------------------------------------------------------\n","def minimal_founder_cover_set(G: nx.DiGraph) -> set:\n","    \"\"\"\n","    Return one minimal founder cover (greedy) as a Python set.\n","    \"\"\"\n","    #different founder condition than used in score enhancement (no stipulation on genotype)\n","    founders = [n for n in G if G.in_degree(n) == 0]\n","    cover, uncovered = set(), set(G.nodes)\n","    while uncovered:\n","        best = max(founders, key=lambda f: len(nx.descendants(G, f) & uncovered) + (f in uncovered))\n","        cover.add(best)\n","        uncovered -= nx.descendants(G, best)\n","        uncovered.discard(best)\n","    return cover\n","\n","def minimal_founder_coverage_size(G: nx.DiGraph) -> float:\n","    \"\"\"\n","    Return the size of the minimal founder coverage set.\n","    \"\"\"\n","    return len(minimal_founder_cover_set(G))\n","\n","# ---------------------------------------------------------------------\n","# 9. Founder Influence\n","# ---------------------------------------------------------------------\n","def founder_influence(G) -> Dict[str, float]:\n","    phen = nx.get_node_attributes(G, \"phenotype\")\n","    affected = {n for n, p in phen.items() if p == 2}\n","    memo_all, memo_aff = {}, {}\n","    def paths(u, memo, target=None):\n","        key = (u, id(target))\n","        if key in memo: return memo[key]\n","        total = 1 if target is None or u in target else 0\n","        for v in G.successors(u):\n","            total += paths(v, memo, target)\n","        memo[key] = total\n","        return total\n","    infl = {}\n","    for f in (n for n in G if G.in_degree(n)==0):\n","        all_p = paths(f, memo_all, None)\n","        aff_p = paths(f, memo_aff, affected)\n","        infl[f] = aff_p / all_p if all_p else 0\n","    return infl\n","\n","\n","# ---------------------------------------------------------------------\n","# GRAPH METRICS WRAPPER\n","# ---------------------------------------------------------------------\n","def graph_metrics(G):\n","    metrics = {**basic_graph_metrics(G), **centralities(G)}\n","    metrics['transitive_reduction_ratio'] = transitive_reduction_ratio(G)\n","    #metrics = {**metrics, **power_law_exponent(G)}\n","    #metrics['sigma_small_world'] = sigma_small_world(G)\n","    metrics['width'] = pedigree_width(G)\n","    metrics['longest_path'] = longest_path_length(G)\n","    metrics['founder_cover_size'] = minimal_founder_coverage_size(G)\n","    metrics['founder_influence'] = founder_influence(G)\n","\n","    return metrics\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kYcXKMyuwj22"},"source":["###Scoring Metrics"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1755352910128,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"qLmo24Mgsnfs"},"outputs":[],"source":["#################### MODULAR VARIANT SCORING ####################\n","'''\n","Scores: measures of variant association likelihoods accounting for graph/pedigree structure as well as genotype and phenotype data,\n","provided in mode agnostic form\n","\n","Current List of Scores:\n","-------------------------\n","\n","'''\n","#----------------------------------------------------------------------\n","# 1v2. Edge Consistency\n","#----------------------------------------------------------------------\n","def edge_consistency(G, gt):\n","    \"\"\"\n","    Fraction of parent→child edges whose genotype transition is Mendelian-\n","    compatible under the specified inheritance mode.\n","    gt is a dict {node: 0/1/2}.\n","\n","    Given working off of genotypes, mode is irrelevant.\n","    \"\"\"\n","    #partental genotype (pg,mg) | (mg,pg) --> possible child genotypes {}\n","    BOTH_PARENT_ALLOWED_INHERITENCE = {\n","        (0,0):{0}, (1,0):{0,1}, (1,1):{0,1,2}, (2,1):{1,2}, (2,0):{1}, (2,2):{2}\n","    }\n","    SINGLE_PARENT_ALLOWED_INHERITENCE = {\n","        0:{0,1}, 1:{0,1,2}, 2:{1,2}\n","    }\n","\n","    sequenced_samples = gt.keys()\n","\n","    good=0; total=0\n","    for child in G.nodes:\n","        if child not in sequenced_samples:\n","            continue\n","\n","        prnts=parents(G,child)\n","        sequenced_prnts = [p for p in prnts if p in sequenced_samples]\n","\n","\n","        if len(sequenced_prnts) == 1:\n","            if gt[child] in SINGLE_PARENT_ALLOWED_INHERITENCE.get(gt.get(sequenced_prnts[0]), {}):\n","                good+=1\n","            total+=1\n","        elif len(sequenced_prnts) == 2:\n","            gp,gm=[gt[p] for p in sequenced_prnts]\n","            par_gt = (gp,gm) if (gp,gm) in BOTH_PARENT_ALLOWED_INHERITENCE.keys() else (gm,gp)\n","            if gt[child] in BOTH_PARENT_ALLOWED_INHERITENCE.get(par_gt, {}):\n","                good+=2\n","            total+=2\n","        # If neither parent is sequenced, we cannot check Mendelian consistency for this child, so we skip.\n","\n","\n","    return good/total if total > 0 else 0\n","\n","# ---------------------------------------------------------------------\n","# 2. Generation Continuity\n","# ---------------------------------------------------------------------\n","def generation_continuity(G, gt):\n","    \"\"\"\n","    Return the fraction of generations with carriers (by genotype)\n","    \"\"\"\n","    gen = generations(G)\n","    gens_total = max(gen.values())+1\n","    sequenced_samples = gt.keys()\n","    alt_gens = {gen[n] for n in sequenced_samples if gt[n]>0}\n","    sequenced_gens = {gen[n] for n in sequenced_samples}\n","    return len(alt_gens)/len(sequenced_gens) if sequenced_gens else 0\n","\n","\n","\n","# ---------------------------------------------------------------------\n","# 3v2. Betweeness of Carriers in Affected+Carrier Subgraph\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct based on necessary inclusion of genotype data\n","which is not included in pedigree graph alone\n","'''\n","def carrier_betweenness(G, gt):\n","    aff_nodes = aff(G)\n","    unaff_nodes = unaff(G)\n","    sequenced_samples = gt.keys()\n","    sequenced_unaff_nodes = list(set(unaff_nodes) & set(sequenced_samples))\n","    carrier_nodes = [n for n in sequenced_unaff_nodes if gt[n] == 1]\n","    carrier_aff_subgraph = G.subgraph(aff_nodes+carrier_nodes)\n","    subgraph_bet = nx.betweenness_centrality(carrier_aff_subgraph, normalized= False)\n","    complete_bet = nx.betweenness_centrality(G, normalized= False)\n","    avg_carrier_betweenness = np.mean([subgraph_bet[n] for n in carrier_aff_subgraph.nodes]) if len(carrier_nodes) > 0 else 0\n","    avg_complete_betweenness = np.mean([complete_bet[n] for n in G.nodes]) if len(G.nodes) > 0 else 0\n","\n","    adj_carrier_betweenness = avg_carrier_betweenness/avg_complete_betweenness if avg_complete_betweenness else 0\n","\n","    return adj_carrier_betweenness\n","\n","\n","# ---------------------------------------------------------------------\n","# VARIANT SCORING WRAPPER\n","# ---------------------------------------------------------------------\n","'''\n","Mode agnostics raw variant scores\n","'''\n","def variant_scores(G, gt):\n","    return {\n","        'edge_consistency': edge_consistency(G, gt),\n","        'generation_continuity': generation_continuity(G, gt),\n","        'carrier_betweenness': carrier_betweenness(G, gt)\n","    }"]},{"cell_type":"markdown","metadata":{"id":"Yo9kqW91WuaV"},"source":["#VI. Segregation Scoring"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1755352910320,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"JZgbS-EoDHvy"},"outputs":[],"source":["def segregation_network_score(G, gt, mode, Scoring_Method= 'Original', categorical_scores=0, weights={'w_edge':0.6,'w_gen':0.2,'w_bet':0.2}, verbose= False):\n","\n","    #Categorical Score Calculation\n","    if not categorical_scores:\n","\n","        categorical_scores = {}\n","\n","        #edge consistency\n","        categorical_scores['edge_score']= edge_consistency(G,gt)\n","\n","        # generation continuity\n","        categorical_scores['gen_score']= max(0,min(1,generation_continuity(G,gt))) #ensures genscore within [0,1]\n","\n","        # carrier betweenness\n","        cb = carrier_betweenness(G, gt) if mode=='AR' else 1-carrier_betweenness(G, gt)\n","        categorical_scores['bet_score']= max(0,min(1,cb))\n","\n","\n","        #Extended Categorical Scores\n","        if Scoring_Method == 'Extended':\n","            #when incorrect number of weights are given for extended scores, resort to default weights\n","            if len(weights.keys()) < 5:\n","                weights = {'w_edge': 0.6, 'w_gen': 0.1, 'w_bet': 0.1, 'w_found': 0.1, 'w_depth': 0.1}\n","\n","            #average founders influence\n","            sequenced_samples = gt.keys()\n","            founders = [n for n in G if G.in_degree(n)==0 and n in sequenced_samples and gt[n]>0]\n","            if founders:\n","                fi = founder_influence(G)\n","                categorical_scores['found_score'] = sum(fi[f] for f in founders) / len(founders)\n","            else:\n","                categorical_scores['found_score'] = 0\n","\n","            #transitive reduction ratio\n","            categorical_scores['red_score'] = edge_consistency(nx.transitive_reduction(G), gt)\n","\n","            #alternate geneational depth\n","            depth = longest_path_length(G)\n","            sequenced_samples = gt.keys()\n","            alt_nodes = [n for n in sequenced_samples if gt[n]>0]\n","            alt_depth = 0\n","            if depth and founders and alt_nodes:\n","                # shortest founder→alt path for each pair that is connected\n","                lengths = []\n","                for f in founders:\n","                    for a in alt_nodes:\n","                        if nx.has_path(G, f, a):\n","                            lengths.append(nx.shortest_path_length(G, f, a))\n","                if lengths:\n","                    alt_depth = max(lengths)\n","            categorical_scores['depth_score'] = alt_depth / depth\n","\n","            #pedigree width\n","            categorical_scores['width_score'] = pedigree_width(G) / 4\n","\n","            #minimal coverage\n","            cover = minimal_founder_cover_set(G)\n","            categorical_scores['cov_score'] = 0\n","\n","\n","    #Weighted Score Calculation\n","    score = (weights['w_edge'] * categorical_scores['edge_score']) + (weights['w_gen'] * categorical_scores['gen_score']) + (weights['w_bet'] * categorical_scores['bet_score'])\n","    if Scoring_Method == 'Extended':\n","        score += (weights['w_found'] * categorical_scores['found_score']) + (weights['w_depth'] * categorical_scores['depth_score'])\n","\n","    '''\n","    Current Scoring Metrics:\n","        Original:\n","            edge_score\n","            gen_score\n","            bet_score\n","        Extended:\n","            found_score\n","            red_score (CURRENTLY UNUSED)\n","            depth_score\n","            width_score (CURRENTLY UNUSED)\n","            cov_score (CURRENTLY UNUSED)\n","    '''\n","    if verbose:\n","        print(f\"Edge Score: {categorical_scores['edge_score']}; Gen Score: {categorical_scores['gen_score']}; Bet Score: {categorical_scores['bet_score']}\")\n","        if Scoring_Method == 'Extended':\n","            print(f\"Found Score: {categorical_scores['found_score']}; Depth Score: {categorical_scores['depth_score']}\")\n","        print(f'Segregation Score: {score}')\n","    return score, categorical_scores\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xtetVhqEYLt-"},"source":["#IV. Pedigree and Variant Table Simulation"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1755352910327,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"3M3mRkOlYRIs"},"outputs":[],"source":["def pedigree_generator(max_children, FamilyID, mode, generation_count, alt_freq, SpouseLikelihood = 0.75, AffectedSpouse= False, BackpropLikelihood= False):\n","        #-------------------------------------------\n","        # Helper Functions for Pedigree Propigation\n","        #-------------------------------------------\n","\n","        '''\n","        Basic helper function to add new entry to pedigree dataframe\n","        '''\n","        def entry_generator(IndividualID, PaternalID, MaternalID, Sex, Phenotype, Genotype):\n","            nonlocal family_df\n","            family_df.loc[IndividualID] = [FamilyID, PaternalID, MaternalID, Sex, Phenotype, Genotype]\n","\n","        '''\n","        Helper function to translate between genotype and phenotype\n","        Dependant on the mode of inheritance\n","        Input: genotype(int(0,1,2))\n","        Output: phenotype(int(1,2))\n","        '''\n","        def genotype_interpreter(genotype):\n","            if mode == 'AR':\n","                phenotype = 2 if genotype == 2 else 1\n","            if mode == 'AD':\n","                phenotype = 2 if genotype == 2 or genotype == 1 else 1\n","            return phenotype\n","\n","        def calc_inheritance_weights(p,q):\n","\n","            tt = q**4\n","            to = 2*p*(q**3)\n","            tz = (p**2)*(q**2)\n","            oo = 4*(p**2)*(q**2)\n","            oz = 2*(p**3)*(q)\n","            zz = p**4\n","\n","            homoRef = p**2\n","            hetero = 2*p*q\n","            homoAlt = q**2\n","\n","            inheritance_patterns = {\n","                'forward_genotypes': {\n","                #(paternal genotype, maternal genotype) -> [possible child genotypes]\n","                    (2,2): [2],\n","                    (2,1): [2,1],\n","                    (1,2): [2,1],\n","                    (2,0): [1],\n","                    (0,2): [1],\n","                    (1,1): [2,1,0],\n","                    (0,1): [1,0],\n","                    (1,0): [1,0],\n","                    (0,0): [0]\n","                },\n","                'forward_weights': {\n","                    (2,2): [1],\n","                    (2,1): [1,1],\n","                    (1,2): [1,1],\n","                    (2,0): [1],\n","                    (0,2): [1],\n","                    (1,1): [1,2,1],\n","                    (0,1): [1,1],\n","                    (1,0): [1,1],\n","                    (0,0): [1]\n","                },\n","                #child genotype -> [possible (paternal,maternal) genotypes]\n","                'reverse_genotypes': {\n","                    2: [(2,2),(2,1),(1,2),(1,1)],\n","                    1: [(2,1),(1,2),(2,0),(0,2),(1,1),(1,0),(0,1)],\n","                    0: [(1,0),(0,1),(0,0)]\n","                },\n","                'reverse_weights': {\n","                    2: [homoAlt**2, homoAlt*hetero, hetero*homoAlt, hetero**2],\n","                    1: [homoAlt*hetero, hetero*homoAlt, homoAlt*homoRef, homoRef*homoAlt, hetero**2, hetero*homoRef, homoRef*hetero],\n","                    0: [hetero*homoRef, homoRef*hetero, homoRef**2]\n","                }\n","            }\n","\n","            return inheritance_patterns\n","\n","        '''\n","        Wrapper function that generates the primary founder of the pedigree\n","        By default, this individual is affected\n","        If AD, 20% chance homozygous, 80% chance heterozygous.\n","        If AR, 100% chance homozygous.\n","        Input:\n","        Output:\n","        '''\n","        def primary_founder_generator():\n","            nonlocal family_df\n","\n","            if mode == 'AD':\n","                Genotype = random.choices(population= [1,2],\n","                                          weights= (0.8, 0.2))[0]\n","            elif mode == 'AR':\n","                Genotype= 2\n","\n","            entry_generator(IndividualID= 1,\n","                            PaternalID= 0,\n","                            MaternalID= 0,\n","                            Sex= random.randint(1,2),\n","                            Phenotype= 2,\n","                            Genotype= Genotype)\n","        '''\n","        Wrapper function that generates spouses unrelated to primary founder\n","        Spouse sex dependent on the relative of primary founder.\n","        Genotype and phenotype dependent on the mode of inheritance and affected spouse paramter.\n","        Input: relativeID(int)\n","        Ouput: n/a\n","        '''\n","        def spouse_generator(RelativeAnchorID):\n","            nonlocal family_df, alt_freq, ref_freq\n","\n","            pp = ref_freq**2\n","            pq2 = 2*ref_freq*alt_freq\n","            qq = alt_freq**2\n","\n","            Sex= 1 if family_df.loc[RelativeAnchorID]['Sex'] == 2 else 2\n","\n","            if AffectedSpouse:\n","                Genotype= random.choices(population= [0,1,2],\n","                                          weights= (pp, pq2, qq),\n","                                          k=1)[0]\n","\n","            else:\n","                Genotype = 0\n","\n","            entry_generator(IndividualID= len(family_df)+1,\n","                            PaternalID= 0,\n","                            MaternalID= 0,\n","                            Sex= Sex,\n","                            Phenotype= genotype_interpreter(Genotype),\n","                            Genotype= Genotype)\n","        '''\n","        Wrapper function that generates an entry for the child of two given individuals.\n","        Child's genotype is chosen from list of allowed gentypes given parents genotypes with equal likelihood.\n","        Input: PaternalID(int), MaternalID(int)\n","        Output: n/a\n","        '''\n","        def child_generator(PaternalID, MaternalID):\n","            nonlocal family_df, inheritance_patterns\n","\n","            parentalGenotype = (int(family_df.loc[PaternalID]['Genotype']), int(family_df.loc[MaternalID]['Genotype']))\n","\n","            Genotype = random.choices(population= inheritance_patterns['forward_genotypes'][parentalGenotype],\n","                                      weights= inheritance_patterns['forward_weights'][parentalGenotype],\n","                                      k=1)[0]\n","\n","            entry_generator(IndividualID= len(family_df)+1,\n","                            PaternalID= PaternalID,\n","                            MaternalID= MaternalID,\n","                            Sex= random.randint(1,2),\n","                            Phenotype= genotype_interpreter(Genotype),\n","                            Genotype= Genotype)\n","        #---------------------------------------\n","        # Primary Pedigree Contruction Functions\n","        #---------------------------------------\n","        '''\n","        Function that recursively constructs pedigree in backward direction.\n","        Infers ancestors of individuals unrelated to primary founder as they are added.\n","        Input: current_generation(int), RealativeAnchorID(int)\n","        Output: n/a\n","        '''\n","        def recursive_history_backprop(current_generation, RelativeAnchorID):\n","            nonlocal family_df, generation_count, inheritance_patterns, BackpropLikelihood\n","\n","            BackpropRNG = random.randint(1,100)/100\n","\n","            if current_generation > 0 and BackpropRNG <= BackpropLikelihood:\n","\n","                GenotypeTup = random.choices(population= inheritance_patterns['reverse_genotypes'][family_df.loc[RelativeAnchorID]['Genotype']],\n","                                                    weights= inheritance_patterns['reverse_weights'][family_df.loc[RelativeAnchorID]['Genotype']],\n","                                                    k=1)[0]\n","\n","                ID_list = ['PaternalID', 'MaternalID']\n","\n","                for i in range(2):\n","                    entry_generator(IndividualID= len(family_df)+1,\n","                                    PaternalID= 0,\n","                                    MaternalID= 0,\n","                                    Sex= 1 + i,\n","                                    Phenotype= genotype_interpreter(GenotypeTup[i]),\n","                                    Genotype= GenotypeTup[i])\n","                    family_df.at[RelativeAnchorID, ID_list[i]] = len(family_df)\n","                    recursive_history_backprop(current_generation-1, len(family_df))\n","\n","        '''\n","        Function that recursively constructs pedigree in forward direction.\n","        Input: current_generation(int), RelativeAnchorID(int)\n","        Output: n/a\n","        '''\n","        def recursive_pedigree_construction(current_generation, RelativeAnchorID):\n","            nonlocal family_df, max_children, generation_count\n","\n","            if current_generation < generation_count-1:\n","\n","                spouse_generator(RelativeAnchorID= RelativeAnchorID)\n","\n","                #Determining Parental Sex for next generation\n","                if family_df.loc[RelativeAnchorID]['Sex'] == 1:\n","                    PaternalID = RelativeAnchorID\n","                    MaternalID = len(family_df)\n","                else:\n","                    PaternalID = len(family_df)\n","                    MaternalID = RelativeAnchorID\n","\n","                if BackpropLikelihood:\n","                    recursive_history_backprop(current_generation, len(family_df))\n","\n","                for child in range(random.randint(1, max_children)):\n","                    child_generator(PaternalID= PaternalID, MaternalID= MaternalID)\n","                    reproduction_rng = random.randint(1,100)/100\n","                    if reproduction_rng <= SpouseLikelihood:\n","                        recursive_pedigree_construction(current_generation+1, len(family_df))\n","\n","\n","        #-------------------------------------\n","        # 1. Construct the empty data frame\n","        #-------------------------------------\n","        pedigree_construction_columns = ['FamilyID', 'IndividualID', 'PaternalID', 'MaternalID', 'Sex', 'Phenotype', 'Genotype']\n","        family_df = pd.DataFrame(columns= pedigree_construction_columns)\n","        family_df.set_index('IndividualID', inplace=True)\n","\n","        #-------------------------------------\n","        # 2. Generating Primary Founder\n","        #-------------------------------------\n","        primary_founder_generator()\n","\n","        #--------------------------------------------\n","        # 3. Construct Inheritence Pattern Dictionary\n","        #--------------------------------------------\n","        ref_freq = 1 - alt_freq\n","        inheritance_patterns = calc_inheritance_weights(ref_freq, alt_freq)\n","\n","        #----------------------------------------\n","        # 4. Generating Pedigree\n","        #----------------------------------------\n","        recursive_pedigree_construction(current_generation= 0, RelativeAnchorID= 1)\n","\n","        #-------------------------------\n","        # 5. Resetign Standard Indexing\n","        #-------------------------------\n","        family_df.reset_index(inplace= True)\n","\n","        return family_df"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1755352910327,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"LK4mG_nUW7yE"},"outputs":[],"source":["def simulate_variant_table(G, mode='AD', n_bg=5, linked_variant_gt_skeleton = False):\n","    samples = list(G.nodes)\n","    sequenced_samples = []\n","    for s in samples:\n","        if s in linked_variant_gt_skeleton.keys():\n","            sequenced_samples.append(s)\n","    phen = nx.get_node_attributes(G,'phenotype')\n","    vars = {}\n","    # causal\n","    causal = 'chr1:100000_A>T'\n","    if linked_variant_gt_skeleton:\n","        vars[causal] = linked_variant_gt_skeleton\n","    else:\n","        raise NotImplementedError\n","    # background\n","    for i in range(n_bg):\n","        vid=f'chr1:{100200+i}_G>C'\n","        vars[vid]={s:random.choices([0,1,2],[0.8,0.18,0.02])[0] for s in sequenced_samples}\n","    return vars\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1755352910344,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"},"user_tz":-60},"id":"OCxKc2AtkgfE"},"outputs":[],"source":["from os import link\n","def pedigree_group_generator(pedigree_count, mode, max_children, generation_count, n_bg= 5, alt_freq = 0, sequence_coverage=0.5):\n","    Fam_Data_Dict = {}\n","    for Family_Num in range(1, pedigree_count+1):\n","        FamilyID = f'FAM{Family_Num}'\n","\n","        #for cases in which alt_frequency is not given (defaults are mode-dependent)\n","        if not alt_freq:\n","          alt_freq = random.randint(2,8)/100 if mode == 'AD' else random.randint(5,20)/100\n","\n","        QC_checks = 0\n","        ped_QC_pass = False\n","        while not ped_QC_pass:\n","            QC_checks += 1\n","            ped_df = pedigree_generator(max_children= max_children,\n","                                        FamilyID= FamilyID,\n","                                        mode= mode,\n","                                        generation_count= generation_count,\n","                                        alt_freq= alt_freq,\n","                                        BackpropLikelihood= random.choice([0.25,0.5,0.75]),\n","                                        AffectedSpouse= True)\n","            ped_dg = construct_pedigree_graph(ped_df)\n","            affected_nodes = aff(ped_dg)\n","            if len(affected_nodes) > 1 and len(ped_dg.nodes()) >= (generation_count * 2):\n","                ped_QC_pass = True\n","            elif QC_checks >= 50:\n","                print(f'{mode} {FamilyID}: Failed QC checks, included despite QC failure to prioritize futher operations')\n","                ped_QC_pass = True\n","\n","        var_QC_pass = False\n","        while not var_QC_pass:\n","            linked_variant_gt_skeleton = {key: value for key, value in zip(ped_df['IndividualID'], ped_df['Genotype'])}\n","\n","            all_indv = list(linked_variant_gt_skeleton.keys())\n","            for indv in all_indv:\n","                linked_variant_gt_skeleton[indv] = int(linked_variant_gt_skeleton[indv])\n","\n","                #culling genotype data for realizing sequencing coverage\n","                sequencing_rng = random.randint(1,100)/100\n","                if sequencing_rng > sequence_coverage:\n","                    linked_variant_gt_skeleton.pop(indv)\n","            if len(linked_variant_gt_skeleton) > 2:\n","                var_QC_pass = True\n","\n","        var_dict = simulate_variant_table(G= ped_dg,\n","                                          mode= mode,\n","                                          n_bg= n_bg,\n","                                          linked_variant_gt_skeleton= linked_variant_gt_skeleton)\n","        cat_score_dict = {}\n","        for VarID in var_dict.keys():\n","            _, cat_score_dict[VarID] = segregation_network_score(G= ped_dg,\n","                                                                 gt= var_dict[VarID],\n","                                                                 mode= mode,\n","                                                                 Scoring_Method= 'Extended')\n","\n","        Fam_Data_Dict[FamilyID] = {'PedGraph': ped_dg, 'VarTable': var_dict, 'CategoricalScores': cat_score_dict}\n","    return Fam_Data_Dict"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"BiGLM8TKeQ8a","executionInfo":{"status":"ok","timestamp":1755352910397,"user_tz":-60,"elapsed":52,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["ped_AD = '''\\\n","FAM1 1 0 0 1 2\n","FAM1 2 0 0 2 1\n","FAM1 3 1 2 1 2\n","FAM1 4 1 2 2 1\n","FAM1 5 0 0 2 1\n","FAM1 6 3 5 1 2\n","FAM1 7 3 5 2 1\n","FAM1 8 0 0 1 1\n","'''\n","open('ad_complete.ped','w').write(ped_AD)\n","\n","\n","ped_AR = '''\\\n","FAM2 1 0 0 1 1\n","FAM2 2 0 0 2 1\n","FAM2 3 1 2 1 1\n","FAM2 4 1 2 2 1\n","FAM2 10 0 0 1 1\n","FAM2 11 0 0 2 1\n","FAM2 5 3 11 1 2\n","FAM2 6 3 11 2 1\n","FAM2 7 4 10 2 2\n","FAM2 8 4 10 1 1\n","'''\n","open('ar_complete.ped','w').write(ped_AR)\n","\n","DF_ad = pedfile_readin('ad_complete.ped')\n","DF_ar = pedfile_readin('ar_complete.ped')\n","G_ad = construct_pedigree_graph(DF_ad)\n","G_ar = construct_pedigree_graph(DF_ar)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"B57GEisQTpe2","executionInfo":{"status":"ok","timestamp":1755352949897,"user_tz":-60,"elapsed":39483,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["AD_Fam_Data = pedigree_group_generator(pedigree_count= 100,\n","                                       mode= 'AD',\n","                                       max_children= 3,\n","                                       generation_count= 3,\n","                                       n_bg= 9,\n","                                       sequence_coverage= 0.25)\n","AR_Fam_Data = pedigree_group_generator(pedigree_count= 100,\n","                                       mode= 'AR',\n","                                       max_children= 3,\n","                                       generation_count= 3,\n","                                       n_bg= 9)"]},{"cell_type":"markdown","metadata":{"id":"YZ_NP-9adN_O"},"source":["#V. Mode of Inheritence Classification"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"lVVvhnvoaOvo","executionInfo":{"status":"ok","timestamp":1755352977059,"user_tz":-60,"elapsed":25,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def trial_based_feature_threshold_determination(generation_count,\n","                                                trial_count=1000,\n","                                                max_children= 3,\n","                                                AD_alt_freq_range= (2,10),\n","                                                AR_alt_freq_range= (5,20),\n","                                                verbose = True,\n","                                                size_agnostic = False,\n","                                                accuracy_threshold = 0.7):\n","    '''\n","    Determines optimal inheritence pattern determination thresholds for pedigrees of given generation count\n","    based on a given number of randomly generated trial pedigrees\n","    '''\n","\n","    def trial_pedigree_generation():\n","        nonlocal generation_count, trial_count, AD_alt_freq_range, AR_alt_freq_range, max_children, size_agnostic\n","\n","        all_trial_pedigree_features = pd.DataFrame()\n","\n","        for trialID in range(1, trial_count+1):\n","            famID = 'TestFam' + str(trialID)\n","            actual_mode = random.choice(['AD', 'AR'])\n","            alt_freq_min = AD_alt_freq_range[0] if actual_mode == 'AD' else AR_alt_freq_range[0]\n","            alt_freq_max = AD_alt_freq_range[1] if actual_mode == 'AD' else AR_alt_freq_range[1]\n","            alt_freq = random.randint(alt_freq_min, alt_freq_max)/100\n","\n","            #Accounting for cases where we want thresholds that are not specific to a generation count\n","            if size_agnostic:\n","                #Run time seems to increase indefinitely if left to be size_agnostic so currently unusable feature\n","                trial_generation_count = random.randint(2, generation_count)\n","            else:\n","                trial_generation_count = generation_count\n","\n","            QC_pass = False\n","            while not QC_pass:\n","                trial_pedigree_df = pedigree_generator(FamilyID= famID,\n","                                                       mode= actual_mode,\n","                                                       max_children= random.randint(2,max_children),\n","                                                       generation_count= trial_generation_count,\n","                                                       AffectedSpouse= True,\n","                                                       BackpropLikelihood= random.choice([0.25, 0.5, 0.75]),\n","                                                       alt_freq= alt_freq)\n","                trial_pedigree_dg = construct_pedigree_graph(trial_pedigree_df)\n","\n","                affecteded_nodes = aff(trial_pedigree_dg)\n","                if len(affecteded_nodes) > 1 and len(trial_pedigree_dg.nodes()) > (generation_count * 2) - 1:\n","                    QC_pass = True\n","\n","\n","            trial_feat_met_dict = {**pedigree_features(trial_pedigree_dg), **graph_metrics(trial_pedigree_dg)}\n","            trial_feat_met_dict['actual_mode'] = actual_mode\n","            trial_feat_met_df = pd.DataFrame(trial_feat_met_dict, index= [0])\n","\n","            all_trial_pedigree_features = pd.concat(objs= [all_trial_pedigree_features, trial_feat_met_df], ignore_index=True)\n","\n","        return all_trial_pedigree_features\n","\n","\n","\n","\n","    def ROC_param_calc(true_labels, predicted_labels):\n","        real_pos_count = 0\n","        real_neg_count = 0\n","        true_pos_count = 0\n","        false_pos_count = 0\n","\n","        for i in range(len(true_labels)):\n","            if true_labels[i] == 'AD':\n","                real_pos_count += 1\n","                if predicted_labels[i] == 'AD':\n","                    true_pos_count += 1\n","            elif true_labels[i] == 'AR':\n","                real_neg_count += 1\n","                if predicted_labels[i] == 'AD':\n","                    false_pos_count += 1\n","\n","\n","        TPR = true_pos_count/real_pos_count\n","        FPR = false_pos_count/real_neg_count\n","\n","        return TPR, FPR\n","\n","    def AUC_calc(FPR_scores, TPR_scores):\n","        FPR_arr = np.array(FPR_scores)\n","        TPR_arr = np.array(TPR_scores)\n","\n","        sort_indx = np.argsort(FPR_arr)\n","        FPR_arr = FPR_arr[sort_indx]\n","        TPR_arr = TPR_arr[sort_indx]\n","\n","        auc_score = auc(FPR_arr, TPR_arr)\n","\n","        return auc_score\n","\n","    def ROC_plot(features, TPR_score_dict, FPR_score_dict):\n","\n","        fig = plt.figure()\n","        ax = plt.subplot(111)\n","\n","        for feature in features:\n","            AUC_score = AUC_calc(FPR_scores= FPR_score_dict[feature],\n","                                 TPR_scores= TPR_score_dict[feature])\n","            ax.plot(FPR_score_dict[feature], TPR_score_dict[feature],\n","                    label= f'{feature} = {AUC_score:.2f}')\n","\n","        ax.plot([0,1], [0,1], linestyle='--', color='gray')\n","        ax.set_xlabel('False Positive Rate')\n","        ax.set_ylabel('True Positive Rate')\n","        ax.set_title(f'Mode of Inheritance ROC')\n","        ax.grid(True)\n","\n","        box= ax.get_position()\n","        ax.set_position([box.x0, box.y0, box.width*0.8, box.height])\n","        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n","                  ncol= 2, fancybox=True, shadow=True)\n","\n","\n","    def single_feature_threshold_determination(feature_values, actual_mode_labels):\n","        min_value = min(feature_values)\n","        max_value = max(feature_values)\n","        thresh_increment = (max_value - min_value)/100\n","        min_value = min_value - thresh_increment\n","        threshold_options = [min_value+(thresh_increment*i) for i in range(103)]\n","\n","        best_threshold = None\n","        best_accuracy = 0\n","        best_direction = None\n","\n","        #Test accuracy of each threshold (both as upper and lower limit of AD classification) and store accuracy score\n","        TPR_scores = []\n","        FPR_scores = []\n","        for threshold in threshold_options:\n","            greater_equal_predictions = ['AD' if value > threshold else 'AR' for value in feature_values]\n","            less_predictions = ['AD' if value <= threshold else 'AR' for value in feature_values]\n","\n","            greater_equal_accuracy = accuracy_score(actual_mode_labels, greater_equal_predictions)\n","            less_accuracy = accuracy_score(actual_mode_labels, less_predictions)\n","\n","            if greater_equal_accuracy > best_accuracy:\n","                best_accuracy = greater_equal_accuracy\n","                best_threshold = threshold\n","                best_direction = 'greater'\n","            elif less_accuracy > best_accuracy:\n","                best_accuracy = less_accuracy\n","                best_threshold = threshold\n","                best_direction = 'less_equal'\n","\n","            TPR, FPR = ROC_param_calc(actual_mode_labels, greater_equal_predictions)\n","            TPR_scores.append(TPR)\n","            FPR_scores.append(FPR)\n","\n","        return best_threshold, best_direction, best_accuracy, TPR_scores, FPR_scores\n","\n","    accuracy_checks = 0\n","    max_accuracy_checks = 3\n","    accuracy_QC_pass = False\n","    while not accuracy_QC_pass and accuracy_checks < max_accuracy_checks:\n","        accuracy_checks += 1\n","        trial_features_df = trial_pedigree_generation()\n","        training_features_df = trial_features_df.sample(frac=0.8)\n","        testing_features_df = trial_features_df.drop(training_features_df.index)\n","\n","\n","\n","        TPR_scores_dict = {}\n","        FPR_scores_dict = {}\n","        thresholds_dict = {}\n","        for feature in trial_features_df.columns.values:\n","            if feature == 'FamID' or feature == 'actual_mode':\n","                continue\n","            threshold, direction, accuracy, TPR_scores, FPR_scores = single_feature_threshold_determination(training_features_df[feature].values,\n","                                                                                                            training_features_df['actual_mode'].values)\n","            thresholds_dict[feature] = {'threshold': threshold, 'direction': direction, 'accuracy': accuracy}\n","            TPR_scores_dict[feature] = TPR_scores\n","            FPR_scores_dict[feature] = FPR_scores\n","\n","        mode_prediction_field = []\n","        for _,row in testing_features_df.iterrows():\n","            predicted_mode = inheritance_pattern_classification(row,\n","                                                                thresholds_dict = thresholds_dict)\n","            mode_prediction_field.append(predicted_mode)\n","        testing_features_df['predicted_mode'] = mode_prediction_field\n","\n","        overall_classification_accuracy = accuracy_score(y_true= testing_features_df['actual_mode'],\n","                                                         y_pred= testing_features_df['predicted_mode'])\n","\n","        certain_test_results_df = testing_features_df[testing_features_df['predicted_mode']!='Uncertain']\n","        num_certain_results = len(certain_test_results_df)\n","        certain_classification_accuracy = accuracy_score(y_true= certain_test_results_df['actual_mode'],\n","                                                         y_pred= certain_test_results_df['predicted_mode'])\n","\n","        if certain_classification_accuracy >= accuracy_threshold and num_certain_results/len(testing_features_df) >= accuracy_threshold:\n","            accuracy_QC_pass = True\n","\n","\n","\n","    if verbose:\n","        ROC_plot(features= thresholds_dict.keys(),\n","                 TPR_score_dict= TPR_scores_dict,\n","                 FPR_score_dict= FPR_scores_dict)\n","        print(f'Number of Certain Results: {num_certain_results}/{len(testing_features_df)}')\n","        print(f'Certain Classification Accuracy: {certain_classification_accuracy}')\n","        print(f'Overall Classification Accuracy: {overall_classification_accuracy}')\n","\n","    return thresholds_dict\n","\n","def inheritance_pattern_classification(sample_features,\n","                                       thresholds_dict,\n","                                       min_accuracy_score= 0.7) -> str:\n","\n","    votes= 0\n","    total= 0\n","    for feature, descriptors in thresholds_dict.items():\n","        threshold = descriptors['threshold']\n","        direction = descriptors['direction']\n","        accuracy = descriptors['accuracy']\n","        feature_value = sample_features[feature]\n","\n","        if accuracy >= min_accuracy_score:\n","            total += 1\n","            if direction == 'greater':\n","                if feature_value > threshold:\n","                    votes += 1\n","            elif direction == 'less_equal':\n","                if feature_value <= threshold:\n","                    votes += 1\n","\n","    if total == 0:\n","        return 'Uncertain'\n","    elif votes/total > 0.75:\n","        return 'AD'\n","    elif votes/total < 0.25:\n","        return 'AR'\n","    else:\n","        return 'Uncertain'\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"CEMxXPZ6qZUs","executionInfo":{"status":"ok","timestamp":1755352983563,"user_tz":-60,"elapsed":5,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def classify_pedigree(G, thresholds_dict= 0) -> str:\n","    if isinstance(G, nx.DiGraph):\n","        if not thresholds_dict:\n","            thresholds_dict = trial_based_feature_threshold_determination(generation_count= max(generations(G).values())+1)\n","        pedigree_feats_mets = {**pedigree_features(G), **graph_metrics(G)}\n","    else:\n","        raise TypeError(f'Invalid Input Type: classify pedigree takes NetworkX directed graph with optional thresholds dict as input; given {type(G)}')\n","\n","    return inheritance_pattern_classification(sample_features= pedigree_feats_mets,\n","                                              thresholds_dict= thresholds_dict)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xGja9Ffeqc-b","executionInfo":{"status":"ok","timestamp":1755352984934,"user_tz":-60,"elapsed":2,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def classify_multiple_pedigrees(Multi_Ped_Dict: dict, thresholds_dict= 0, same_size= True):\n","    if same_size:\n","        if not thresholds_dict:\n","            threshold_basis_graph = random.choice(list(Multi_Ped_Dict.values()))['PedGraph']\n","            thresholds_dict = trial_based_feature_threshold_determination(generation_count= longest_path_length(threshold_basis_graph)+1)\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            G = Multi_Ped_Dict[FamilyID]['PedGraph']\n","            Multi_Ped_Dict[FamilyID]['pred_mode'] = classify_pedigree(G, thresholds_dict= thresholds_dict)\n","    else:\n","        pedigree_sizes = set()\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            G = Multi_Ped_Dict[FamilyID]['PedGraph']\n","            pedigree_sizes.add(longest_path_length(G)+1)\n","        thresholds_2d_dict = {}\n","        for pedigree_size in pedigree_sizes:\n","            thresholds_2d_dict[pedigree_size] = trial_based_feature_threshold_determination(generation_count= pedigree_size)\n","\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            G = Multi_Ped_Dict[FamilyID]['PedGraph']\n","            Multi_Ped_Dict[FamilyID]['pred_mode'] = classify_pedigree(G, thresholds_dict= thresholds_2d_dict[longest_path_length(G)+1])\n","\n","    return Multi_Ped_Dict"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"dZROSDvkqhi1","executionInfo":{"status":"ok","timestamp":1755352991041,"user_tz":-60,"elapsed":6,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def pedigree_group_mode_agreement(Multi_Ped_Dict: dict):\n","    '''\n","    Returns the mutliple pedigree data file with updated predicted modes as well as the\n","    most prevelant inheritance mode classification found in the predicted modes\n","    '''\n","    Multi_Ped_Dict = classify_multiple_pedigrees(Multi_Ped_Dict)\n","    mode_lst = [Multi_Ped_Dict[FamilyID]['pred_mode'] for FamilyID in Multi_Ped_Dict.keys()]\n","    agreed_mode = max(set(mode_lst), key= mode_lst.count)\n","    return Multi_Ped_Dict, agreed_mode"]},{"cell_type":"markdown","source":["#Segregation Scoring Optimization"],"metadata":{"id":"NBvD-vumOM7a"}},{"cell_type":"markdown","metadata":{"id":"nihCElu5AR0F"},"source":["Scoring Helper Functions"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"5P5K52lqAP28","executionInfo":{"status":"ok","timestamp":1755352998874,"user_tz":-60,"elapsed":16,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def max_score_highlighter(s):\n","    is_max = s == s.max()\n","    return [\n","        'background-color: green' if max_score and varID == 'chr1:100000_A>T'\n","        else 'background-color: red' if max_score\n","        else ''\n","        for varID, max_score in zip(s.index, is_max)]"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pbJVknj6B-Ye","executionInfo":{"status":"ok","timestamp":1755353084459,"user_tz":-60,"elapsed":41,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def pprint_weights(weights_dict):\n","    for weight_name, weight_value in weights_dict.items():\n","        weight_value = round(weight_value, 3)\n","        print(f'{weight_name}: {weight_value}')\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"HjPwmZdTet7Q"},"source":["Weights Optimization"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"YAOqvAgiewgS","executionInfo":{"status":"ok","timestamp":1755353086476,"user_tz":-60,"elapsed":23,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["#Margin Objective Function\n","def margin_weight_optimization_objective(weights_lst, Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode):\n","\n","    weights_dict = {weight_names[i]: weights_lst[i] for i in range(len(weight_names))}\n","    margins = []\n","    for FamilyID, FamilyData in Multi_Ped_Dict.items():\n","        G, VarTable = FamilyData['PedGraph'], FamilyData['VarTable']\n","        CategoricalScores = FamilyData['CategoricalScores'][linked_variant]\n","        linked_score, _ = segregation_network_score(G= G,\n","                                                 gt= VarTable[linked_variant],\n","                                                 mode= mode,\n","                                                 Scoring_Method= Scoring_Method,\n","                                                 weights= weights_dict,\n","                                                 categorical_scores= CategoricalScores)\n","\n","        unlinked_scores = []\n","        for VarID, gt in VarTable.items():\n","            if VarID != linked_variant:\n","                CategoricalScores = FamilyData['CategoricalScores'][VarID]\n","                unlinked_score, _ = segregation_network_score(G= G,\n","                                                            gt= VarTable[VarID],\n","                                                            mode= mode,\n","                                                            Scoring_Method= Scoring_Method,\n","                                                            weights= weights_dict,\n","                                                            categorical_scores= CategoricalScores)\n","                unlinked_scores.append(unlinked_score)\n","\n","        max_unlinked_score = max(unlinked_scores)\n","\n","        margin = linked_score - max_unlinked_score\n","        margins.append(margin)\n","\n","    avg_margin = np.mean(margins)\n","\n","    return 1 - avg_margin\n","\n","\n","#Fraction Objective Function\n","def rank_weight_optimization_objective(weights_lst, Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode):\n","\n","    weights_dict = {weight_names[i]: weights_lst[i] for i in range(len(weight_names))}\n","    correct = 0\n","    total = 0\n","    ranked_margins = []\n","    for FamilyID, FamilyData in Multi_Ped_Dict.items():\n","        G, VarTable = FamilyData['PedGraph'], FamilyData['VarTable']\n","        CategoricalScores = FamilyData['CategoricalScores'][linked_variant]\n","        linked_score, _ = segregation_network_score(G= G,\n","                                                 gt= VarTable[linked_variant],\n","                                                 mode= mode,\n","                                                 Scoring_Method= Scoring_Method,\n","                                                 weights= weights_dict,\n","                                                 categorical_scores= CategoricalScores)\n","\n","        unlinked_scores = []\n","        for VarID, gt in VarTable.items():\n","            if VarID != linked_variant:\n","                CategoricalScores = FamilyData['CategoricalScores'][VarID]\n","                unlinked_score, _ = segregation_network_score(G= G,\n","                                                            gt= VarTable[VarID],\n","                                                            mode= mode,\n","                                                            Scoring_Method= Scoring_Method,\n","                                                            weights= weights_dict,\n","                                                            categorical_scores= CategoricalScores)\n","                unlinked_scores.append(unlinked_score)\n","\n","        all_scores = unlinked_scores + [linked_score]\n","        max_unlinked_score = max(unlinked_scores)\n","        avg_unlinked_score = np.mean(unlinked_scores)\n","\n","        all_scores.sort(reverse=True)\n","        linked_score_rank = all_scores.index(linked_score) + 1\n","\n","        margin = linked_score - max_unlinked_score\n","\n","\n","        ranked_margins.append(linked_score_rank*margin)\n","\n","\n","\n","    avg_ranked_margin = np.mean(ranked_margins)\n","\n","\n","    return len(VarTable) - avg_ranked_margin\n","\n","\n","#Optimization Wrapper\n","def weights_optimization(Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, Optimization_Method, initial_guess, mode= 'AD'):\n","    n_weights = len(weight_names)\n","    bounds = [(0.001,1)]*n_weights\n","    constraints = {'type': 'eq',\n","                  #figure out how this function is working\n","                  'fun': lambda w: np.sum(w)-1}\n","\n","    if Optimization_Method == 'Margin':\n","        results = minimize(fun= margin_weight_optimization_objective,\n","                          x0= initial_guess,\n","                          args= (Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode),\n","                          bounds= bounds,\n","                          constraints= constraints)\n","    elif Optimization_Method == 'Rank':\n","        results = minimize(fun= rank_weight_optimization_objective,\n","                          x0= initial_guess,\n","                          args= (Multi_Ped_Dict, linked_variant, weight_names, Scoring_Method, mode),\n","                          bounds= bounds,\n","                          constraints= constraints)\n","\n","    #Directly attaching weights with their names as dictionary for ease of use is scoring wrapper function\n","    optimized_weights = {weight_names[i]: results.x[i] for i in range(len(weight_names))}\n","\n","    return optimized_weights"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"MWp9RgLyvoKr","executionInfo":{"status":"ok","timestamp":1755353089742,"user_tz":-60,"elapsed":15,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def segregation_scoring_wrapper(Multi_Ped_Dict: dict,\n","                                Scoring_Method= 'Original',\n","                                weights= 0,\n","                                Optimization_Method= 'None',\n","                                Verbose= True,\n","                                Known_Linked_Var= False,\n","                                Known_Mode= 0):\n","    '''\n","    Takes multi-pedigree data dictionaries as input and outputs the dictionary with updated scores\n","    '''\n","    if not Known_Mode:\n","        Multi_Ped_Dict, agreed_mode = pedigree_group_mode_agreement(Multi_Ped_Dict)\n","    else:\n","        agreed_mode = Known_Mode\n","\n","    if Scoring_Method == 'Original':\n","        weight_names = ['w_edge', 'w_gen', 'w_bet']\n","    elif Scoring_Method == 'Extended':\n","        weight_names = ['w_edge', 'w_gen', 'w_bet', 'w_found', 'w_depth']\n","\n","    #manually assignment of weights if no weights given if using original scoring\n","    if not weights:\n","        if Scoring_Method == 'Original':\n","            weights= {\n","                'w_edge': 0.6,\n","                'w_gen': 0.2,\n","                'w_bet': 0.2\n","            }\n","        elif Scoring_Method == 'Extended':\n","            weights= {\n","                'w_edge': 0.6,\n","                'w_gen': 0.1,\n","                'w_bet': 0.1,\n","                'w_found': 0.1,\n","                'w_depth': 0.1,\n","            }\n","        if Optimization_Method == 'None':\n","            print(f'Default {Scoring_Method} Weights:')\n","        elif Optimization_Method == 'Margin' or Optimization_Method == 'Rank':\n","            initial_guess = []\n","            for weight_name in weight_names:\n","                initial_guess.append(weights[weight_name])\n","\n","            training_Multi_Ped_Dict = {}\n","            test_Multi_Ped_Dict = {}\n","            tt_split = 0.8\n","            for FamilyID in Multi_Ped_Dict.keys():\n","                if int(FamilyID[3:]) <= int(tt_split*len(Multi_Ped_Dict)):\n","                    training_Multi_Ped_Dict[FamilyID] = Multi_Ped_Dict[FamilyID]\n","                else:\n","                    test_Multi_Ped_Dict[FamilyID] = Multi_Ped_Dict[FamilyID]\n","            #Downsize the original multiple pedigree dict to the testing data now that we have done training testing split\n","            Multi_Ped_Dict = test_Multi_Ped_Dict\n","            weights= weights_optimization(Multi_Ped_Dict= training_Multi_Ped_Dict,\n","                                          linked_variant= Known_Linked_Var,\n","                                          weight_names= weight_names,\n","                                          Scoring_Method= Scoring_Method,\n","                                          Optimization_Method= Optimization_Method,\n","                                          mode= agreed_mode,\n","                                          initial_guess= initial_guess)\n","            print(f'{Optimization_Method} Optimized {Scoring_Method} Weights:')\n","        else:\n","            raise NotImplementedError(f'Invalid Optimization Method: {Optimization_Method}')\n","\n","\n","\n","    else:\n","        print(f'Given {Scoring_Method} Weights:')\n","\n","    pprint_weights(weights)\n","\n","\n","    All_Family_Score_df = pd.DataFrame(columns=Multi_Ped_Dict.keys())\n","    for FamilyID in Multi_Ped_Dict.keys():\n","\n","        PedGraph, VarTable = Multi_Ped_Dict[FamilyID]['PedGraph'], Multi_Ped_Dict[FamilyID]['VarTable']\n","\n","        if not Known_Mode:\n","            pred_mode = Multi_Ped_Dict[FamilyID]['pred_mode']\n","        else:\n","            pred_mode = Known_Mode\n","\n","        CategoricalScores = Multi_Ped_Dict[FamilyID]['CategoricalScores']\n","        #convert uncertain classified pedigrees to AD (can change scoring to accomodate later)\n","        #currently using agreed mode for scoring parameter so should not matter\n","        if pred_mode == 'Uncertain':\n","           pred_mode = 'AD'\n","\n","        Multi_Ped_Dict[FamilyID][Scoring_Method] = {}\n","        for VarID in VarTable.keys():\n","            score, _ = segregation_network_score(G= PedGraph,\n","                                                  gt= VarTable[VarID],\n","                                                  mode= agreed_mode,\n","                                                  Scoring_Method= Scoring_Method,\n","                                                  weights= weights,\n","                                                  categorical_scores= CategoricalScores[VarID])\n","            Multi_Ped_Dict[FamilyID][Scoring_Method][VarID] = score\n","\n","\n","        All_Family_Score_df[FamilyID] = Multi_Ped_Dict[FamilyID][Scoring_Method]\n","\n","    if Known_Linked_Var:\n","        Correctly_Scored_Pedigrees = 0\n","        for FamilyID in Multi_Ped_Dict.keys():\n","            if max(Multi_Ped_Dict[FamilyID][Scoring_Method], key= Multi_Ped_Dict[FamilyID][Scoring_Method].get) == Known_Linked_Var:\n","                Correctly_Scored_Pedigrees += 1\n","        Scoring_Method_Accuracy = Correctly_Scored_Pedigrees/len(Multi_Ped_Dict)\n","\n","    #displaying scores if verbose option chosen\n","    if Verbose:\n","        #printing dataframe with highest scoring variant highlighted for each family\n","        print(f'{Scoring_Method} Segregation Scoring Results')\n","        styled_All_Family_Score_df = All_Family_Score_df.style.apply(max_score_highlighter, axis=0)\n","        display(styled_All_Family_Score_df)\n","        print(f'{Scoring_Method} Segregation Scoring Accuracy: {Scoring_Method_Accuracy}')\n","\n","\n","\n","    return Multi_Ped_Dict, weights, Scoring_Method_Accuracy\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Zf41qMcnjTNi"},"source":["#Pedigree Size and Scoring Performance"]},{"cell_type":"markdown","source":["Optimization Method Comparisons"],"metadata":{"id":"Q3eJu6ggOf0T"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"glI-QdfUncWv","executionInfo":{"status":"ok","timestamp":1755353094372,"user_tz":-60,"elapsed":13,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def segregation_scoring_performance_test(Generation_Count,\n","                                         Pedigree_Count,\n","                                         Variant_Count,\n","                                         Mode= 'AD',\n","                                         Max_Children= 3,\n","                                         Known_Linked_Var= 'chr1:100000_A>T',\n","                                         Verbose= False,\n","                                         VarScore_Readout= False,\n","                                         SequenceCoverage= 0.5):\n","    Multi_Ped_Dict = pedigree_group_generator(pedigree_count= Pedigree_Count,\n","                                              generation_count= Generation_Count,\n","                                              max_children= Max_Children,\n","                                              n_bg= Variant_Count-1,\n","                                              mode= Mode,\n","                                              sequence_coverage= SequenceCoverage)\n","    Scoring_Modes = ['Original', 'Extended']\n","    Optimization_Methods = ['None', 'Margin', 'Rank']\n","\n","    scoring_performance_results_dict = {\n","                                          'Optimization Method': Optimization_Methods,\n","                                          'Original': [],\n","                                          'Extended': []\n","                                        }\n","\n","    for scoring_mode in Scoring_Modes:\n","        for optimization_method in Optimization_Methods:\n","            _, _, scoring_perfomance = segregation_scoring_wrapper(Multi_Ped_Dict= Multi_Ped_Dict,\n","                                                                    Scoring_Method= scoring_mode,\n","                                                                    Optimization_Method= optimization_method,\n","                                                                    Verbose= VarScore_Readout,\n","                                                                    Known_Linked_Var= Known_Linked_Var,\n","                                                                    Known_Mode= Mode)\n","            scoring_performance_results_dict[scoring_mode].append(scoring_perfomance)\n","\n","    scoring_performance_results_df = pd.DataFrame.from_dict(scoring_performance_results_dict).set_index('Optimization Method')\n","\n","    if Verbose:\n","        print(f'{Mode} Scoring Performance Results')\n","        display(scoring_performance_results_df)\n","\n","    #return scoring_performance_results_df"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"lAHkq1NtAPeO","colab":{"base_uri":"https://localhost:8080/","height":836},"executionInfo":{"status":"ok","timestamp":1755360488098,"user_tz":-60,"elapsed":42180,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"f258ceac-1f72-46d7-e0e2-1ab882c5c9b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Margin Optimized Original Weights:\n","w_edge: 0.245\n","w_gen: 0.408\n","w_bet: 0.347\n","\n","Rank Optimized Original Weights:\n","w_edge: 0.329\n","w_gen: 0.343\n","w_bet: 0.328\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.091\n","w_bet: 0.443\n","w_found: 0.225\n","w_depth: 0.24\n","\n","Rank Optimized Extended Weights:\n","w_edge: 0.13\n","w_gen: 0.107\n","w_bet: 0.373\n","w_found: 0.255\n","w_depth: 0.135\n","\n","AD Scoring Performance Results\n"]},{"output_type":"display_data","data":{"text/plain":["                     Original  Extended\n","Optimization Method                    \n","None                    0.974     0.957\n","Margin                  0.910     0.905\n","Rank                    0.925     0.930"],"text/html":["\n","  <div id=\"df-31fa9faf-4933-4910-abb0-b0b2a87d42e9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","    <tr>\n","      <th>Optimization Method</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>None</th>\n","      <td>0.974</td>\n","      <td>0.957</td>\n","    </tr>\n","    <tr>\n","      <th>Margin</th>\n","      <td>0.910</td>\n","      <td>0.905</td>\n","    </tr>\n","    <tr>\n","      <th>Rank</th>\n","      <td>0.925</td>\n","      <td>0.930</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31fa9faf-4933-4910-abb0-b0b2a87d42e9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-31fa9faf-4933-4910-abb0-b0b2a87d42e9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-31fa9faf-4933-4910-abb0-b0b2a87d42e9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5a460072-bde0-4925-9038-2a466e1b9d33\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a460072-bde0-4925-9038-2a466e1b9d33')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5a460072-bde0-4925-9038-2a466e1b9d33 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                                     SequenceCoverage= 1)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Optimization Method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None\",\n          \"Margin\",\n          \"Rank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.033471380810079096,\n        \"min\": 0.91,\n        \"max\": 0.974,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.974,\n          0.91,\n          0.925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026006409466386004,\n        \"min\": 0.905,\n        \"max\": 0.957,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.957,\n          0.905,\n          0.93\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["segregation_scoring_performance_test(Generation_Count= 3,\n","                                     Pedigree_Count= 1000,\n","                                     Variant_Count= 10,\n","                                     Mode= 'AD',\n","                                     Max_Children= 3,\n","                                     Verbose= True,\n","                                     SequenceCoverage= 0.75)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"KUHvYTOvFIBt","colab":{"base_uri":"https://localhost:8080/","height":836},"executionInfo":{"status":"ok","timestamp":1755360593796,"user_tz":-60,"elapsed":105693,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"d99f7bea-4a68-4194-b2c2-1554ab9fd363"},"outputs":[{"output_type":"stream","name":"stdout","text":["Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Margin Optimized Original Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.998\n","\n","Rank Optimized Original Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.998\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","Margin Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.93\n","w_found: 0.001\n","w_depth: 0.067\n","\n","Rank Optimized Extended Weights:\n","w_edge: 0.001\n","w_gen: 0.001\n","w_bet: 0.838\n","w_found: 0.001\n","w_depth: 0.159\n","\n","AR Scoring Performance Results\n"]},{"output_type":"display_data","data":{"text/plain":["                     Original  Extended\n","Optimization Method                    \n","None                    0.971     0.975\n","Margin                  0.890     0.885\n","Rank                    0.890     0.910"],"text/html":["\n","  <div id=\"df-79e4b881-343a-4fcf-8fc2-31f4e24fef43\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","    <tr>\n","      <th>Optimization Method</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>None</th>\n","      <td>0.971</td>\n","      <td>0.975</td>\n","    </tr>\n","    <tr>\n","      <th>Margin</th>\n","      <td>0.890</td>\n","      <td>0.885</td>\n","    </tr>\n","    <tr>\n","      <th>Rank</th>\n","      <td>0.890</td>\n","      <td>0.910</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79e4b881-343a-4fcf-8fc2-31f4e24fef43')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-79e4b881-343a-4fcf-8fc2-31f4e24fef43 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-79e4b881-343a-4fcf-8fc2-31f4e24fef43');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-aa05b12d-f217-4bf0-92d6-e0920f28e280\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa05b12d-f217-4bf0-92d6-e0920f28e280')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-aa05b12d-f217-4bf0-92d6-e0920f28e280 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                                     SequenceCoverage= 1)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Optimization Method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None\",\n          \"Margin\",\n          \"Rank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04676537180435966,\n        \"min\": 0.89,\n        \"max\": 0.971,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.89,\n          0.971\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04645786621588783,\n        \"min\": 0.885,\n        \"max\": 0.975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.975,\n          0.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["segregation_scoring_performance_test(Generation_Count= 3,\n","                                     Pedigree_Count= 1000,\n","                                     Variant_Count= 10,\n","                                     Mode= 'AR',\n","                                     Max_Children= 3,\n","                                     Verbose= True,\n","                                     SequenceCoverage= 0.75)"]},{"cell_type":"markdown","source":["Pedigree Size Scoring Comparison"],"metadata":{"id":"qlSdFzOyOjJJ"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"zAIlfuBJHbvI","executionInfo":{"status":"ok","timestamp":1755353108578,"user_tz":-60,"elapsed":7,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["def pedigree_size_performance_test(Generation_Range,\n","                                   Pedigree_Count,\n","                                   Variant_Count,\n","                                   Optimization_Method,\n","                                   Mode,\n","                                   max_children= 3,\n","                                   Known_Linked_Var= 'chr1:100000_A>T',\n","                                   Verbose= False,\n","                                   VarScore_Readout= False,\n","                                   SequenceCoverage= 0.5):\n","    pedigree_size_scoring_results_dict = {\n","        'Pedigree Size': [],\n","        'Original': [],\n","        'Extended': []\n","    }\n","    min_gen = Generation_Range[0]\n","    max_gen = Generation_Range[1]\n","    for i in range(min_gen, max_gen+1):\n","        pedigree_size_scoring_results_dict['Pedigree Size'].append(i)\n","\n","    for Gen_Count in range(min_gen, max_gen+1):\n","        Fam_Data = pedigree_group_generator(pedigree_count= Pedigree_Count,\n","                                            generation_count= Gen_Count,\n","                                            max_children= max_children,\n","                                            n_bg= Variant_Count-1,\n","                                            mode= Mode,\n","                                            sequence_coverage= SequenceCoverage)\n","        print(f'GENERATION COUNT= {Gen_Count} ')\n","        for Scoring_Method in ['Original', 'Extended']:\n","            _, _, Scoring_Accuracy = segregation_scoring_wrapper(Multi_Ped_Dict= Fam_Data,\n","                                                                  Scoring_Method= Scoring_Method,\n","                                                                  Optimization_Method= Optimization_Method,\n","                                                                  Known_Linked_Var= Known_Linked_Var,\n","                                                                  Known_Mode= Mode,\n","                                                                  Verbose= VarScore_Readout)\n","            pedigree_size_scoring_results_dict[Scoring_Method].append(Scoring_Accuracy)\n","        print()\n","\n","    pedigree_size_scoring_results_df = pd.DataFrame.from_dict(pedigree_size_scoring_results_dict).set_index('Pedigree Size')\n","    if Verbose:\n","        if Optimization_Method == 'None':\n","            print(f'{Mode} Pedigree Unoptimized Size Scoring Results')\n","        else:\n","            print(f'{Mode} Pedigree {Optimization_Method} Optimized Size Scoring Results')\n","        display(pedigree_size_scoring_results_df)\n","\n","    #return pedigree_size_scroing_results_df"]},{"cell_type":"code","source":["pedigree_size_performance_test(Generation_Range= (3,5),\n","                               Pedigree_Count= 500,\n","                               Variant_Count= 10,\n","                               Optimization_Method= 'None',\n","                               Mode= 'AD',\n","                               Verbose= True,\n","                               VarScore_Readout= False,\n","                               SequenceCoverage= 0.75)"],"metadata":{"id":"pj0L7-rz0oto","colab":{"base_uri":"https://localhost:8080/","height":943},"executionInfo":{"status":"ok","timestamp":1755361293902,"user_tz":-60,"elapsed":253561,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"f75aeaf4-730f-447f-f2b3-f19a902b93da"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["GENERATION COUNT= 3 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","GENERATION COUNT= 4 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","GENERATION COUNT= 5 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","AD Pedigree Unoptimized Size Scoring Results\n"]},{"output_type":"display_data","data":{"text/plain":["               Original  Extended\n","Pedigree Size                    \n","3                 0.860     0.728\n","4                 0.762     0.712\n","5                 0.674     0.654"],"text/html":["\n","  <div id=\"df-c60a819c-49d3-4e81-8600-4cf4d17bee57\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","    <tr>\n","      <th>Pedigree Size</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.860</td>\n","      <td>0.728</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.762</td>\n","      <td>0.712</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.674</td>\n","      <td>0.654</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c60a819c-49d3-4e81-8600-4cf4d17bee57')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c60a819c-49d3-4e81-8600-4cf4d17bee57 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c60a819c-49d3-4e81-8600-4cf4d17bee57');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4dd9558f-16f6-4fe4-b04e-b8247bc73382\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dd9558f-16f6-4fe4-b04e-b8247bc73382')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4dd9558f-16f6-4fe4-b04e-b8247bc73382 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                               SequenceCoverage= 0\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Pedigree Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09304479208066042,\n        \"min\": 0.674,\n        \"max\": 0.86,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.86,\n          0.762,\n          0.674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03893584466786354,\n        \"min\": 0.654,\n        \"max\": 0.728,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.728,\n          0.712,\n          0.654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","execution_count":48,"metadata":{"id":"h4xujoMOMxGe","colab":{"base_uri":"https://localhost:8080/","height":943},"executionInfo":{"status":"ok","timestamp":1755361725738,"user_tz":-60,"elapsed":431824,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}},"outputId":"31ac30af-7e62-4cdd-f6b5-16dd389e4b7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["GENERATION COUNT= 3 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","GENERATION COUNT= 4 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","GENERATION COUNT= 5 \n","Default Original Weights:\n","w_edge: 0.6\n","w_gen: 0.2\n","w_bet: 0.2\n","\n","Default Extended Weights:\n","w_edge: 0.6\n","w_gen: 0.1\n","w_bet: 0.1\n","w_found: 0.1\n","w_depth: 0.1\n","\n","\n","AR Pedigree Unoptimized Size Scoring Results\n"]},{"output_type":"display_data","data":{"text/plain":["               Original  Extended\n","Pedigree Size                    \n","3                 0.926     0.906\n","4                 0.938     0.926\n","5                 0.952     0.930"],"text/html":["\n","  <div id=\"df-1f440ea9-20e5-4a56-a78c-67d29725e097\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Original</th>\n","      <th>Extended</th>\n","    </tr>\n","    <tr>\n","      <th>Pedigree Size</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.926</td>\n","      <td>0.906</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.938</td>\n","      <td>0.926</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.952</td>\n","      <td>0.930</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f440ea9-20e5-4a56-a78c-67d29725e097')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1f440ea9-20e5-4a56-a78c-67d29725e097 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1f440ea9-20e5-4a56-a78c-67d29725e097');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f19782d8-d674-4f2b-b929-e48beda779f5\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f19782d8-d674-4f2b-b929-e48beda779f5')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f19782d8-d674-4f2b-b929-e48beda779f5 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"                               SequenceCoverage= 0\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Pedigree Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01301281419729538,\n        \"min\": 0.926,\n        \"max\": 0.952,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.926,\n          0.938,\n          0.952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012858201014657285,\n        \"min\": 0.906,\n        \"max\": 0.93,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.906,\n          0.926,\n          0.93\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["pedigree_size_performance_test(Generation_Range= (3,5),\n","                               Pedigree_Count= 500,\n","                               Variant_Count= 10,\n","                               Optimization_Method= 'None',\n","                               Mode= 'AR',\n","                               Verbose= True,\n","                               VarScore_Readout= False,\n","                               SequenceCoverage= 0.75)"]},{"cell_type":"markdown","source":["#Other Graph Structure Studies"],"metadata":{"id":"E0JL4g3Icuhs"}},{"cell_type":"markdown","source":["##Scale Free Network Analysis and Power Law Assesment"],"metadata":{"id":"cXtlKRyTcxcf"}},{"cell_type":"code","source":["def plot_degree_distribution(PedList, title=\"Degree Distribution\"):\n","    degrees = []\n","    for PedGraph in PedList:\n","        degrees = degrees + [d for n, d in PedGraph.degree()]\n","    fit = powerlaw.Fit(degrees, verbose=False)\n","\n","    fig = fit.plot_pdf(color='b', label='Empirical')\n","    fit.power_law.plot_pdf(color='r', linestyle='--', label='Power law fit', ax=fig)\n","    plt.legend()\n","    plt.title(title + f\"\\nα = {fit.power_law.alpha:.2f}, xmin = {fit.power_law.xmin}\")\n","    plt.xlabel(\"Degree\")\n","    plt.ylabel(\"P(Degree ≥ x)\")\n","    plt.show()\n","\n","    R, p = fit.distribution_compare('power_law', 'exponential')\n","    print(\"Comparison with exponential: R =\", R, \"p =\", p)"],"metadata":{"id":"75nfWW0ac1og","executionInfo":{"status":"aborted","timestamp":1755352950131,"user_tz":-60,"elapsed":106721,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Consanguinity Analysis"],"metadata":{"id":"i-nOSmKPNhEV"}},{"cell_type":"code","source":["def pc_consanguinity_check(PedGraph):\n","    '''\n","    Checks for parent-child consanguinity and returns a dictionary of the parents of child of consanguinity grandchild/child -> (consanguinous parent pair)\n","    '''\n","    trRatio = transitive_reduction_ratio(PedGraph)\n","    if trRatio != 1:\n","        tr_PedGraph = nx.transitive_reduction(PedGraph)\n","        pc_parents = {}\n","        for (u,v) in PedGraph.edges():\n","            if (u,v) not in tr_PedGraph.edges():\n","                pc_parents[v] = parents(PedGraph, v)\n","        return pc_parents\n","    else:\n","        return None\n"],"metadata":{"id":"sywbzCPGNpGf","executionInfo":{"status":"aborted","timestamp":1755352950132,"user_tz":-60,"elapsed":106722,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","def consanguinity_analysis(G, n, ancestor_list):\n","    revG = G.reverse()\n","    parents = list(G.predecessors(n))\n","    ct = Counter(ancestor_list)\n","    common_ancestors = []\n","    for indv, count in ct.items():\n","        if count > 1:\n","            common_ancestors.append(indv)\n","    shortest_p1 = min(nx.shortest_path_length(revG, parents[0], common_ancestor) for common_ancestor in common_ancestors)\n","    shortest_p2 = min(nx.shortest_path_length(revG, parents[1], common_ancestor) for common_ancestor in common_ancestors)\n","    degree_separation = shortest_p1 + shortest_p2\n","    return degree_separation, common_ancestors\n","\n","def ancestor_dictionary_wrapper(G):\n","    founders = [n for n in G if G.in_degree(n)==0]\n","    ancestor_dict = {n:[] for n in G}\n","    consanguinous_nodes = {}\n","\n","    def recur_amend_record(G, n):\n","        nonlocal ancestor_dict\n","        ancestor_list = []\n","        parents = list(G.predecessors(n))\n","        for p in parents:\n","            ancestor_list = ancestor_list + [p] + ancestor_dict[p]\n","\n","        ancestor_setlist = list(set(ancestor_list))\n","        if len(ancestor_setlist) < len(ancestor_list):\n","            degree_separation, common_ancestors = consanguinity_analysis(G, n, ancestor_list)\n","            consanguinous_nodes[n] = {'parents': parents,\n","                                      'degree_separation': degree_separation,\n","                                      'common_ancestor': common_ancestors}\n","\n","        ancestor_dict[n] = ancestor_setlist\n","        for c in G.successors(n):\n","            recur_amend_record(G, c)\n","    for f in founders:\n","        recur_amend_record(G= G, n= f)\n","\n","    return ancestor_dict, consanguinous_nodes"],"metadata":{"id":"Fj0mY2cgugpx","executionInfo":{"status":"aborted","timestamp":1755352950132,"user_tz":-60,"elapsed":106722,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hx1sS4fQ80RZ"},"source":["#**Notes:**\n","*   Removing floaters helped increase differentiation in AD raw score rankings\n","*   Majority of enhanced scoring metrics are unhelpful for classification according to margin maximization efforts\n","*   Changes to betweeness scoring to work off affected and carrier subgraph greatly improved scoring (including mode dependent scoring)\n","*   Fraction based optimization showing the faults in margin based optimization (maybe need to work off of something other than average of margin, add additional boolean gate??)\n","    *  Fraction based optimization does not seem to be acutalually varying the weights and sticking with defaults.\n","      * turns out this is because the fraction is not a smooth function and has large plataues, the minimization function relies on this function being smooth and coninuous with a clear gradient for minimzation\n","    *  Should try penalizing the cases where the incorrect varient recieves the highest score (-1 penality to average margin?) where correctly scored variants have normal margin calculation\n","      * adjusted the fraction optimization to have -0.5 penalty when incorrectly scored (working to mixed results, both optimization techniques range wildly in their efficacy)\n","    *  Optimized weights are consistently under performing compared to default weights for AR scoring, extended scoring providing some benefit (currently doing additive 1.5 bonus for margins that are correctly scored in fraction optimization)\n","    * Initall guesses for optimization were adjusted to be equal to the initial guesses given when foregoing optimization given the defaults were opten out performing defaults in accuracy\n","*   Added testing/training split for cases of weight optimization\n","*   Adjusted betweeness scores:\n","    * network X normalizes scores by default\n","    * previous was scoring carrier betweeness by doing average carrier normalized score for carrier+affected subgraph\n","    * trialed doing subgraph betweeness(avg)/complete betweeness(avg) with both scores being the normalized scores: this resulted in many score values > 1\n","    * tried same scoring metric without normalization: worked well, many scores went to default 0 or 1 but work towards the trends we want for scoring\n","*   Rank Optimization\n","    * Fraction optimization wasn't providing any additional performance over margin optimization (makes sense since I was just basically doing a varied margin optimization, trying to add additional punishment for negative margins)\n","    * Tried new technique that incoorperates where the linked variant score ranks among the other unlinked varient score\n","    * Then multiply that rank by the margin (negative if rank > 1 and positive if rank = 1) adding scaling punshiment for poorly ranking linked variant scores\n","    * In my head, this helps us prioritize correct score rank while maintianing margin increase as a secondary objective (while maintaining a smooth minimization function thanks to margin)\n","    * Overall minimization is done on the averaged ranked_margin values subtracted from the optimal score (max margin (i.e. 1)  x number of variants)\n","        * why am I multiplying the max margin by the number of variants?? the optimal score for the averaged ranked margin would just be 1 right? since the correct variant scoring would result in a rank of 1 and the the highest margin we can expect would be 1 (then the average ranked_margin of a perfectly marked variant would 1?)\n","    * Tried adjusting ranked-based optimization to add extra weight to the ranking over the margin by doing logarithmic scling instead (also tried 2x modifier for >=2 ranking) which did not increase accuracy\n","        * in most cases it lead to a platauing of the minimization function (stayed on default values)\n","*   Scoring Performance Notes:\n","    * Scoring working very well for pedigrees with roughly 10 variants, generation ranging 3-5 (accuracy between 0.9 and 1.0 for all optimization techniques, **FIGURE 1**)\n","    * Increasing the number of variants in vartable severely decreases scoring performance (100 variants reduces accuracy to around 0.7-0.9, **FIGURE 2**)\n","    * Changing the initial guess for weight optimization to default weights used when not optimizing (did this because unoptimized was consistently outperforming optimized weightings): results were neutral with little to no increase in optimization perfmance; will try to adjust optimization methods\n","    * New Ranked Margin Optimization (described above) appears to greatly improve optimization performance (**Figure 4**)\n","      * Testing of new ranked ranking system also appears to improve scoring performance across pedigree size (**Figure 5**)\n","\n","* Computational Performance\n","    * adjusted scoring such that categorical scores only need to calculated once (stored as dictionary within pedigree group data dict) and only need to calculate weighted score using these categorical scores and adjusted weights when optimizing\n","    * This adjustment greatly improved runtime! Example: pedigree size scoring performance compairson runtime >1hr --> 4 min\n","\n","* Incomplete Sequencing Coverage\n","    * Noted that real pedigrees will not have complete sequencing coverage in that not every indiviudal in the pedigree will have sequence data that can be attached to them\n","    * Added necessary caveats to the current scoring metrics to ensure scoring can continue with incomplete sequence coverage\n","    * Added parameter to data generation to similulate incomplete coverage\n","    * As expected, the lower the coverage the lower our scoring accuracy but still able to manage mid 70's - 80's accuracy at 50% coverage\n","    * Now extended scoring is consistent underperforming compared to original scoring\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"5-tuvDRaish-"},"source":["##**FIGURES**\n","**FIGURE 1:** Scoring Optimization Performance Results\n","\n","Samples: 100x 3 generation pedigrees with 10 variants\n","\n","![](https://drive.google.com/uc?id=1xxxUjX1oglAtSuweZzKCVtJrZqTjj7dT)\n","![](https://drive.google.com/uc?id=1aawOmOANQV_f2yp_q6ySbpkVJxsmUaPm)\n","\n","---\n","\n","**FIGURE 2:** Unoptimized Scoring Performance\n","\n","Samples: 100 AD pedigrees with 100 Variants of specified pedigree size\n","\n","![](https://drive.google.com/uc?id=1ixSKlauYKX-evMNjTSTaTXvvhlVDC-5W)\n","\n","---\n","\n","**FIGURE 3:** Scoring Optimization Performance (defaults as initial guess for optimization)\n","\n","Samples: 100x 3 generation pedigrees with 10 variants\n","\n","![](https://drive.google.com/uc?id=1JlIELcjfSio2hxIOG6ZtFsuR1g1PGFqp)\n","![](https://drive.google.com/uc?id=1ZnuRAOrl3EQ2txmOXZbH10LEC2Z_CoTS)\n","\n","---\n","\n","**FIGURE 4:** Scoring Optimization Performance (new ranked margin optimization used under fraction optimization naming)\n","\n","Samples: 50x 3 generation pedigrees with 10 variants\n","\n","![](https://drive.google.com/uc?id=1Wzm8g_u6AGGg2nmXQlziORXVTnc6wlpM)\n","![](https://drive.google.com/uc?id=1ayRKxydz1qgdMkx8CCYCmPx8cwY-EJqj)\n","\n","---\n","\n","**Figure 5:** Unoptimized vs Ranked Optimized Scoring across Pedigree (with larger variant count)\n","\n","Samples: 50x 3-5 generation pedigrees with 50 variants\n","\n","AD Pedigree Scoring:\n","\n","![](https://drive.google.com/uc?id=1j7E-qgS_1ocLo6nxvumwVjjwQUP4qTCB)\n","![](https://drive.google.com/uc?id=1Z7hPdTiFiCPSewrA-6xswaLdjJeroUxl)\n","\n","\n","AR Pedigree Scoring:\n","\n","![](https://drive.google.com/uc?id=1K-8YELWd5GOBC_xmTlC1EYTqVuDVF7L8)\n","![](https://drive.google.com/uc?id=1nQsrxfbTLR2RvkD5_XsgCOHmtrPuvTsd)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jtIyHxUSLlqN"},"source":["#Testbed"]},{"cell_type":"markdown","metadata":{"id":"kxskRlZdLpC3"},"source":["Transverse Reduction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2gAy0Fc7HEM","executionInfo":{"status":"aborted","timestamp":1755352950133,"user_tz":-60,"elapsed":106723,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["testG_AD = copy.deepcopy(G_ad)\n","testG_AD.add_node(8, family='FAM1', sex=1, phenotype=2)\n","testG_AD.add_edge(1, 8)\n","testG_AD.add_edge(4, 8)\n","\n","test_trG_AD = nx.transitive_reduction(testG_AD)\n","test_trG_AD.add_nodes_from(testG_AD.nodes(data=True))\n","test_trG_AD.add_edges_from((u, v, testG_AD.edges[u,v]) for u, v in test_trG_AD.edges)\n","\n","plot_pedigree_tree(testG_AD, title=\"Consanguinous Addition (AD)\")\n","plot_pedigree_tree(test_trG_AD, title=\"Transitive Reduction Consaguinous Addtion (AD)\")\n","\n","\n","trG_AD = nx.transitive_reduction(G_ad)\n","trG_AD.add_nodes_from(G_ad.nodes(data=True))\n","trG_AD.add_edges_from((u, v, G_ad.edges[u,v]) for u, v in trG_AD.edges)\n","\n","plot_pedigree_tree(G_ad, title=\"Original (AD)\")\n","plot_pedigree_tree(trG_AD, title=\"Transitive Reduction (AD)\")\n","\n","pprint(dag_summary(G_ad))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajr33NUmTU4P","executionInfo":{"status":"aborted","timestamp":1755352950133,"user_tz":-60,"elapsed":106723,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["# ---------------------------------------------------------------------\n","# 1v1. Original Edge Consistency Scoring\n","# ---------------------------------------------------------------------\n","def old_edge_consistency(G, gt, mode=\"AD\"):\n","    \"\"\"\n","    Fraction of parent→child edges whose genotype transition is Mendelian-\n","    compatible under the specified inheritance mode.\n","    gt is a dict {node: 0/1/2}.\n","    \"\"\"\n","    ALLOWED_INHERITENCE = {\n","        'AD': {(0,0):{0}, (1,0):{0,1}, (0,1):{0,1}, (1,1):{0,1,2}, (2,_):{1,2}},\n","        'AR': {(0,0):{0}, (1,0):{0,1}, (0,1):{0,1}, (1,1):{0,1,2}, (2,_):{1,2}},\n","    }\n","    good=0; total=0\n","    for child in G:\n","        prnts=parents(G,child)\n","        gp,gm=[gt.get(p,0) for p in prnts+[0,0]][:2]\n","        par_gt = (gp,gm) if (gp,gm) in ALLOWED_INHERITENCE[mode] else (gm,gp)\n","        par_gt = (2,_) if par_gt not in ALLOWED_INHERITENCE[mode] else par_gt\n","        if gt[child] in ALLOWED_INHERITENCE[mode][par_gt]:\n","            good+=1\n","        total+=1\n","    return good/total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqUhge2sTpUW","executionInfo":{"status":"aborted","timestamp":1755352950134,"user_tz":-60,"elapsed":106724,"user":{"displayName":"Nick Taylor","userId":"05080371095151330199"}}},"outputs":[],"source":["# ---------------------------------------------------------------------\n","# 3v1. Carrier Betweeness\n","# ---------------------------------------------------------------------\n","'''\n","Currently defunct so as to trial subgraph version that prunes graph to affected nodes and carriers\n","'''\n","def old_carrier_betweenness(G, gt):\n","    phen = nx.get_node_attributes(G, \"phenotype\")\n","    het_car=[n for n in G if gt[n]==1 and phen[n]!=2]\n","\n","    if het_car:\n","        bet = nx.betweenness_centrality(G)\n","        cb = sum(bet[n] for n in het_car)/len(het_car)\n","        cb /= max(bet.values()) if bet else 1\n","        return cb\n","    else:\n","        return 0"]}],"metadata":{"colab":{"collapsed_sections":["KBxiRyiFWqXw","U3iisDMaYWZj","IkjU5ec4asuu","YZ_NP-9adN_O"],"provenance":[],"mount_file_id":"1ODGtCL1RD4AUrJx96JoioTVgQajy3IOK","authorship_tag":"ABX9TyONyDpB8E1eF1Hxtws+pCag"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}